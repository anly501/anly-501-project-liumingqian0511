<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
  <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    <div class="container-fluid">
      <a class="navbar-brand" href="../index.html">ANLY501</a>
      <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarColor02" aria-controls="navbarColor02" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarColor02">
        <ul class="navbar-nav me-auto">
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/anly501/anly-501-project-liumingqian0511/tree/main/codes">Code</a>
          </li>
          <!-- Introduction -->
          <li class="nav-item">
            <a class="nav-link" href="./introduction00.html">Introduction</a>
          </li>
          <!-- Data Gathering -->
          <li class="nav-item">
            <a class="nav-link" href="./text_gather.html">Data Gathering</a>
          </li>
          <!-- Record Data -->
          <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle" data-bs-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">Record Data</a>
            <div class="dropdown-menu">
              <a class="dropdown-item" href="./record_data_cleaning.html">Cleaning</a>
              <a class="dropdown-item" href="./Record_Data_Exploring.html">Exploring</a>
            </div>
          </li>
          <!-- Text Data -->
          <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle" data-bs-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">Text Data</a>
            <div class="dropdown-menu">
              <a class="dropdown-item" href="./text_clean.html">Cleaning</a>
              <a class="dropdown-item" href="./text_data_explore.html">Exploring</a>
            </div>
          </li>
          <!-- NB -->
          <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle" data-bs-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">Naive Bayes</a>
            <div class="dropdown-menu">
              <a class="dropdown-item" href="./record_NB.html">Record data</a>
              <a class="dropdown-item" href="./textNB.html">Text data</a>
            </div>
          </li>
          <!-- Classification -->
          <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle" data-bs-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">Classification</a>
            <div class="dropdown-menu">
              <a class="dropdown-item" href="./decision_tree.html">Decision Tree</a>
              <a class="dropdown-item" href="./svm_text.html">SVM</a>
            </div>
          </li>
          <!-- Clustering -->
          <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Clustering</a>
            <div class="dropdown-menu">
              <a class="dropdown-item" href="./intro_cluster.html">Intro & Theory</a>
              <a class="dropdown-item" href="./Methods_page.html">Method & Result</a>
              <a class="dropdown-item" href="./Conlusion.html">Conclusion</a>
            </div>
          </li>
          <!-- ARM -->
          <li class="nav-item">
            <a class="nav-link" href="./arm.html">ARM</a>
          </li>
          <!-- Conclusion -->
          <li class="nav-item">
            <a class="nav-link" href="./conclusion00.html">Conclusion</a>
          </li>
          <!-- Data -->
          <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle" data-bs-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">Data</a>
            <div class="dropdown-menu">
              <a class="dropdown-item" href="#">Raw</a>
              <a class="dropdown-item" href="#">Modified</a>
            </div>
          </li>
        </ul>
      </div>
    </div>
  </nav>
<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.251">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2022-11-29">

<title>Text Data Cleaning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="text_clean_files/libs/clipboard/clipboard.min.js"></script>
<script src="text_clean_files/libs/quarto-html/quarto.js"></script>
<script src="text_clean_files/libs/quarto-html/popper.min.js"></script>
<script src="text_clean_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="text_clean_files/libs/quarto-html/anchor.min.js"></script>
<link href="text_clean_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="text_clean_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="text_clean_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="text_clean_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="text_clean_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#read-in-the-json-files" id="toc-read-in-the-json-files" class="nav-link" data-scroll-target="#read-in-the-json-files">Read in the Json files</a></li>
  <li><a href="#assign-labels-manually" id="toc-assign-labels-manually" class="nav-link" data-scroll-target="#assign-labels-manually">Assign Labels Manually</a></li>
  <li><a href="#sentiment-analysis" id="toc-sentiment-analysis" class="nav-link" data-scroll-target="#sentiment-analysis">Sentiment Analysis</a></li>
  <li><a href="#filter-stopwords" id="toc-filter-stopwords" class="nav-link" data-scroll-target="#filter-stopwords">Filter Stopwords</a></li>
  <li><a href="#lemmatization" id="toc-lemmatization" class="nav-link" data-scroll-target="#lemmatization">Lemmatization</a></li>
  <li><a href="#tidy-dataframe" id="toc-tidy-dataframe" class="nav-link" data-scroll-target="#tidy-dataframe">Tidy Dataframe</a></li>
  <li><a href="#vectorization" id="toc-vectorization" class="nav-link" data-scroll-target="#vectorization">Vectorization</a></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Text Data Cleaning</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">November 29, 2022</p>
    </div>
  </div>
    
  </div>
  

</header>

<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk<span class="op">;</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> CountVectorizer</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.corpus <span class="im">import</span> wordnet</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.tokenize <span class="im">import</span> word_tokenize</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.stem <span class="im">import</span> WordNetLemmatizer</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.stem <span class="im">import</span> PorterStemmer</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.corpus <span class="im">import</span> stopwords</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> string </span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.sentiment <span class="im">import</span> SentimentIntensityAnalyzer</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os, json</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> glob</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.corpus <span class="im">import</span> wordnet <span class="im">as</span> wn</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<section id="introduction" class="level3">
<h3 class="anchored" data-anchor-id="introduction">Introduction</h3>
<p>This page will show you how I cleaned up the text data that I gathered from Twitter API. The cleaning of text data is very different from that of record data. The goal of text data cleanup is to make raw text standardized and uniform in format for later analysis. The text data to be cleaned on this page is gathered from Twitter API. So each unit in the data is a tweet posted by the user.</p>
</section>
<section id="read-in-the-json-files" class="level3">
<h3 class="anchored" data-anchor-id="read-in-the-json-files">Read in the Json files</h3>
<p>The first step is to read the JSON file that needs to be cleaned and open it with the pd.read_json() function. One good thing about the pd.read_json() function is that every JSON file opened with it automatically converts to a data frame which is more operable. I assigned the file to ‘health_insurance_df’. I created an ‘ID’ column that takes the value from 1 to the length of the data frame for later use. After adding the ‘ID’ column, we can see that the data frame consists of 6 columns, we are going to focus on the ‘text’ column for cleaning purpose.</p>
<div class="cell" data-execution_count="2">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">#path_to_json = '/Users/liumingqian/anly-501-project-liumingqian0511/data/00-raw-data/twitter_data/'</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> readFiles(path):</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    json_pattern <span class="op">=</span> os.path.join(path,<span class="st">'*.json'</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    file_list <span class="op">=</span> glob.glob(json_pattern)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> pd.read_json(file_list[<span class="dv">0</span>]) <span class="co"># an empty list to store the data frames</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">#print(df.head())</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> <span class="bu">file</span> <span class="kw">in</span> file_list[<span class="dv">1</span>:]:</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>        data <span class="op">=</span> pd.read_json(<span class="bu">file</span>) <span class="co"># read data frame from json file</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>        <span class="co">#print(data.head())</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>        df <span class="op">=</span> pd.concat([df,data],axis<span class="op">=</span><span class="dv">0</span>, ignore_index<span class="op">=</span><span class="va">True</span>) <span class="co"># append the data frame to the list</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">#df = pd.concat(dfs,sort=False) # concatenate all the data frames in the list.</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> readFiles(<span class="st">'/Users/liumingqian/anly-501-project-liumingqian0511/data/00-raw-data/insurance_co'</span>)</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>df.drop_duplicates(subset <span class="op">=</span> <span class="st">'text'</span>, inplace <span class="op">=</span> <span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="3">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>df1 <span class="op">=</span> pd.read_json(<span class="st">'/Users/liumingqian/anly-501-project-liumingqian0511/data/00-raw-data/insurance_co/Aetna.json'</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>df2 <span class="op">=</span> pd.read_json(<span class="st">'/Users/liumingqian/anly-501-project-liumingqian0511/data/00-raw-data/insurance_co/Anthem.json'</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>df3 <span class="op">=</span> pd.read_json(<span class="st">'/Users/liumingqian/anly-501-project-liumingqian0511/data/00-raw-data/insurance_co/Cigna.json'</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>df4 <span class="op">=</span> pd.read_json(<span class="st">'/Users/liumingqian/anly-501-project-liumingqian0511/data/00-raw-data/insurance_co/Humana.json'</span>)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>df5 <span class="op">=</span> pd.read_json(<span class="st">'/Users/liumingqian/anly-501-project-liumingqian0511/data/00-raw-data/insurance_co/UnitedHealth.json'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="assign-labels-manually" class="level3">
<h3 class="anchored" data-anchor-id="assign-labels-manually">Assign Labels Manually</h3>
<div class="cell" data-execution_count="4">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>df1[<span class="st">'label'</span>] <span class="op">=</span> <span class="st">'Aetna'</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>df2[<span class="st">'label'</span>] <span class="op">=</span> <span class="st">'Anthem'</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>df3[<span class="st">'label'</span>] <span class="op">=</span> <span class="st">'Cigna'</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>df4[<span class="st">'label'</span>] <span class="op">=</span> <span class="st">'Humana'</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>df5[<span class="st">'label'</span>] <span class="op">=</span> <span class="st">'UnitedHealth'</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.concat([df1,df2,df3,df4,df5],ignore_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>df.drop_duplicates(subset<span class="op">=</span><span class="st">'text'</span>,inplace <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df[df[<span class="st">'lang'</span>] <span class="op">==</span> <span class="st">'en'</span>]</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>df.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="40">
<pre><code>(269, 7)</code></pre>
</div>
</div>
</section>
<section id="sentiment-analysis" class="level3">
<h3 class="anchored" data-anchor-id="sentiment-analysis">Sentiment Analysis</h3>
<p>The next step of text data cleaning is to perform sentiment analysis for each tweet and store the outcome of each tweet as its label. Sentiment analysis is a technique that detects the underlying sentiment in a piece of text. It is the process of classifying text as either positive, negative, or neutral. Sentiment analysis is very essential to gauge customers’ or users’ responses. In the following chunks, I wrote a getSentiments() function to rate each tweet’s sentiment scores in positivity, negativity, and neutrality. I converted the result from the dictionary to a data frame ‘score’, and also added a column ‘ID’ that takes the same value as the ‘ID’ column in the health_insurance_df. Displaying the first ten rows of the score data frame, we can see that we have four columns of values to rate the corresponding sentiment and one column of ‘ID’ for later use.</p>
<div class="cell" data-execution_count="5">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> getSentiments(df):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    sia <span class="op">=</span> SentimentIntensityAnalyzer()</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    tweet_str <span class="op">=</span> <span class="st">""</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    tweetscore <span class="op">=</span> []</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> tweet <span class="kw">in</span> df[<span class="st">'text'</span>]:</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>        tweet_str <span class="op">=</span> tweet_str <span class="op">+</span> <span class="st">" "</span> <span class="op">+</span> tweet</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>        score <span class="op">=</span> sia.polarity_scores(tweet_str)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>        tweetscore.append(score)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tweetscore</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>sentiment <span class="op">=</span> getSentiments(df)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> pd.DataFrame.from_dict(sentiment)</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> score.assign(ID <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">1</span>,<span class="bu">len</span>(score)<span class="op">+</span><span class="dv">1</span>)))</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>score.head(<span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="41">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>neg</th>
      <th>neu</th>
      <th>pos</th>
      <th>compound</th>
      <th>ID</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.000</td>
      <td>1.000</td>
      <td>0.000</td>
      <td>0.0000</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.000</td>
      <td>1.000</td>
      <td>0.000</td>
      <td>0.0000</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.000</td>
      <td>1.000</td>
      <td>0.000</td>
      <td>0.0000</td>
      <td>3</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.085</td>
      <td>0.878</td>
      <td>0.037</td>
      <td>-0.7278</td>
      <td>4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.080</td>
      <td>0.895</td>
      <td>0.025</td>
      <td>-0.8485</td>
      <td>5</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.071</td>
      <td>0.907</td>
      <td>0.022</td>
      <td>-0.8485</td>
      <td>6</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.080</td>
      <td>0.901</td>
      <td>0.019</td>
      <td>-0.9137</td>
      <td>7</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.067</td>
      <td>0.882</td>
      <td>0.051</td>
      <td>-0.6116</td>
      <td>8</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.052</td>
      <td>0.844</td>
      <td>0.104</td>
      <td>0.9533</td>
      <td>9</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.048</td>
      <td>0.840</td>
      <td>0.112</td>
      <td>0.9692</td>
      <td>10</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="6">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.assign(ID <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">1</span>,<span class="bu">len</span>(df)<span class="op">+</span><span class="dv">1</span>)))</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.merge(score,how<span class="op">=</span><span class="st">'inner'</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'sentiment'</span>] <span class="op">=</span>df[[<span class="st">'neg'</span>,<span class="st">'neu'</span>,<span class="st">'pos'</span>]].idxmax(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'sent_binary'</span>] <span class="op">=</span> df[[<span class="st">'neg'</span>,<span class="st">'pos'</span>]].idxmax(axis <span class="op">=</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="filter-stopwords" class="level3">
<h3 class="anchored" data-anchor-id="filter-stopwords">Filter Stopwords</h3>
<p>Next, I am going to remove the stop words from the text. Stopwords are words which does not add much meaning to a sentence. They can safely be ignored without sacrificing the meaning of the sentence. For example, the words like the, I, it, etc. Such words are already captured in a corpus named corpus. We first download it to our python environment. I wrote a define function to loop through each tweet and to filter out stopwords and lowercase all the letters. Applying this function to our data frame, we can see that the ‘text’ column is now stopwords-free.</p>
<div class="cell" data-execution_count="7">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> filterStopwords(df):</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> val, tweet <span class="kw">in</span> <span class="bu">enumerate</span>(df[<span class="st">'text'</span>]):</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>        new_text<span class="op">=</span><span class="st">""</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> word <span class="kw">in</span> nltk.tokenize.word_tokenize(tweet):</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>            word <span class="op">=</span> word.lower()</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> word <span class="kw">not</span> <span class="kw">in</span> nltk.corpus.stopwords.words(<span class="st">'english'</span>) <span class="kw">and</span> word <span class="kw">not</span> <span class="kw">in</span> [<span class="st">"."</span>,<span class="st">","</span>,<span class="st">"!"</span>,<span class="st">"?"</span>,<span class="st">":"</span>,<span class="st">";"</span>,<span class="st">")"</span>,<span class="st">"("</span>,<span class="st">"'"</span>,<span class="st">"$"</span>,<span class="st">'https'</span>,<span class="st">'co'</span>,<span class="st">'rt'</span>,<span class="st">'@'</span>,<span class="st">'de'</span>,<span class="st">'la'</span>,<span class="st">'the'</span>]:</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>                    new_text<span class="op">+=</span>word<span class="op">+</span><span class="st">" "</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>            df[<span class="st">'text'</span>][val] <span class="op">=</span> new_text</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>filterStopwords(df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="lemmatization" class="level3">
<h3 class="anchored" data-anchor-id="lemmatization">Lemmatization</h3>
<div class="cell" data-execution_count="8">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>lemmatizer <span class="op">=</span> WordNetLemmatizer()</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> lemmatize(df):</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i,tweet <span class="kw">in</span> <span class="bu">enumerate</span>(df[<span class="st">'text'</span>]):</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>        new_text <span class="op">=</span> <span class="st">""</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> word <span class="kw">in</span> tweet.split(<span class="st">' '</span>):</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> wn.synsets(word):</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>                new_text <span class="op">+=</span> lemmatizer.lemmatize(word,pos<span class="op">=</span> wn.synsets(word)[<span class="dv">0</span>].pos()) <span class="op">+</span> <span class="st">" "</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>                new_text <span class="op">+=</span> word <span class="op">+</span> <span class="st">" "</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>        df[<span class="st">'text'</span>][i] <span class="op">=</span> new_text</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>lemmatize(df)</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="44">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>id</th>
      <th>edit_history_tweet_ids</th>
      <th>text</th>
      <th>created_at</th>
      <th>lang</th>
      <th>author_id</th>
      <th>label</th>
      <th>ID</th>
      <th>neg</th>
      <th>neu</th>
      <th>pos</th>
      <th>compound</th>
      <th>sentiment</th>
      <th>sent_binary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1579944177819070464</td>
      <td>[1579944177819070465]</td>
      <td>loyolaramblers 𝗧𝗵𝗲 𝗥𝗮𝗺𝗯𝗹𝗲𝗿 𝗥𝗼𝘂𝗻𝗱𝘁𝗮𝗯𝗹𝗲 present ...</td>
      <td>2022-10-11 21:17:00+00:00</td>
      <td>en</td>
      <td>1015398717392687104</td>
      <td>Aetna</td>
      <td>1</td>
      <td>0.000</td>
      <td>1.000</td>
      <td>0.000</td>
      <td>0.0000</td>
      <td>neu</td>
      <td>neg</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1579940514522370048</td>
      <td>[1579940514522370048]</td>
      <td>pom_pnw aetna give directory resident house ad...</td>
      <td>2022-10-11 21:02:27+00:00</td>
      <td>en</td>
      <td>1325197299409182720</td>
      <td>Aetna</td>
      <td>2</td>
      <td>0.000</td>
      <td>1.000</td>
      <td>0.000</td>
      <td>0.0000</td>
      <td>neu</td>
      <td>neg</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1579937294152519680</td>
      <td>[1579937294152519680]</td>
      <td>peds_ortho aetna ’ doctor ’ office take copay ...</td>
      <td>2022-10-11 20:49:39+00:00</td>
      <td>en</td>
      <td>1228846428929380352</td>
      <td>Aetna</td>
      <td>3</td>
      <td>0.000</td>
      <td>1.000</td>
      <td>0.000</td>
      <td>0.0000</td>
      <td>neu</td>
      <td>neg</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1579934089695875072</td>
      <td>[1579934089695875072]</td>
      <td>aetna twice deny necessary medication b/c what...</td>
      <td>2022-10-11 20:36:55+00:00</td>
      <td>en</td>
      <td>1077754392433082368</td>
      <td>Aetna</td>
      <td>4</td>
      <td>0.085</td>
      <td>0.878</td>
      <td>0.037</td>
      <td>-0.7278</td>
      <td>neu</td>
      <td>neg</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1579932311864238080</td>
      <td>[1579932311864238080]</td>
      <td>peds_ortho aetna pay copay meet oop limit ’ pa...</td>
      <td>2022-10-11 20:29:51+00:00</td>
      <td>en</td>
      <td>1228846428929380352</td>
      <td>Aetna</td>
      <td>5</td>
      <td>0.080</td>
      <td>0.895</td>
      <td>0.025</td>
      <td>-0.8485</td>
      <td>neu</td>
      <td>neg</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="tidy-dataframe" class="level3">
<h3 class="anchored" data-anchor-id="tidy-dataframe">Tidy Dataframe</h3>
<p>After inner joining the score data with the health_insurance_df data so that each tweet in the health_insurance data frame will have corresponding sentiment scores, the basic Text cleaning was done. Now we’re going to finish up our data frame by renaming columns to more intuitive names, casting the data type, and adding a column to display the label of the tweet sentiment.</p>
<div class="cell" data-execution_count="9">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'created_at'</span>] <span class="op">=</span> df[<span class="st">'created_at'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x.date)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>df.rename(columns<span class="op">=</span>{<span class="st">'created_at'</span>:<span class="st">'date'</span>,<span class="st">'lang'</span>:<span class="st">'language'</span>},inplace <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>df.drop(columns <span class="op">=</span> [<span class="st">'author_id'</span>,<span class="st">'id'</span>,<span class="st">'edit_history_tweet_ids'</span>,<span class="st">'neg'</span>,<span class="st">'pos'</span>,<span class="st">'neu'</span>,<span class="st">'compound'</span>],inplace <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="45">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>text</th>
      <th>date</th>
      <th>language</th>
      <th>label</th>
      <th>ID</th>
      <th>sentiment</th>
      <th>sent_binary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>loyolaramblers 𝗧𝗵𝗲 𝗥𝗮𝗺𝗯𝗹𝗲𝗿 𝗥𝗼𝘂𝗻𝗱𝘁𝗮𝗯𝗹𝗲 present ...</td>
      <td>2022-10-11</td>
      <td>en</td>
      <td>Aetna</td>
      <td>1</td>
      <td>neu</td>
      <td>neg</td>
    </tr>
    <tr>
      <th>1</th>
      <td>pom_pnw aetna give directory resident house ad...</td>
      <td>2022-10-11</td>
      <td>en</td>
      <td>Aetna</td>
      <td>2</td>
      <td>neu</td>
      <td>neg</td>
    </tr>
    <tr>
      <th>2</th>
      <td>peds_ortho aetna ’ doctor ’ office take copay ...</td>
      <td>2022-10-11</td>
      <td>en</td>
      <td>Aetna</td>
      <td>3</td>
      <td>neu</td>
      <td>neg</td>
    </tr>
    <tr>
      <th>3</th>
      <td>aetna twice deny necessary medication b/c what...</td>
      <td>2022-10-11</td>
      <td>en</td>
      <td>Aetna</td>
      <td>4</td>
      <td>neu</td>
      <td>neg</td>
    </tr>
    <tr>
      <th>4</th>
      <td>peds_ortho aetna pay copay meet oop limit ’ pa...</td>
      <td>2022-10-11</td>
      <td>en</td>
      <td>Aetna</td>
      <td>5</td>
      <td>neu</td>
      <td>neg</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
</section>
<section id="vectorization" class="level3">
<h3 class="anchored" data-anchor-id="vectorization">Vectorization</h3>
<p>In programming, a vector is a data structure that is similar to a list or an array. For the purpose of an input representation, it is simply a succession of values, with the number of values representing the vector’s “dimensionality.” Text Vectorization is the process of converting text into a numerical representation. I extracted the text from each tweet and save them both to a string for word cloud and to a list for vectorizing. Using the CountVectorizer() function from the sklearn library, we can convert the corpus to a dense matrix. I transformed the matrix to a data frame in which each column takes a word. This gives us a 300 x 1026 huge data frame.</p>
<div class="cell" data-execution_count="10">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>corpus_str <span class="op">=</span> <span class="st">""</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>corpus <span class="op">=</span> []</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'text'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: corpus.append(x))</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>corpus_str <span class="op">=</span> corpus_str.join(corpus)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="11">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>vectorizer<span class="op">=</span>CountVectorizer()</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>Xs  <span class="op">=</span>  vectorizer.fit_transform(corpus)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.array(Xs.todense())</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>col_names<span class="op">=</span>vectorizer.get_feature_names_out()</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>vec <span class="op">=</span> pd.DataFrame(X,columns<span class="op">=</span>col_names)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>vec[<span class="st">'label'</span>] <span class="op">=</span> df[<span class="st">'label'</span>]</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>vec.to_csv(<span class="st">'/Users/liumingqian/anly-501-project-liumingqian0511/data/01-modified-data/vec.csv'</span>)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>vec.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="47">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>00</th>
      <th>000</th>
      <th>01</th>
      <th>02</th>
      <th>08</th>
      <th>0bl5dzrcc2</th>
      <th>0cfllxypoq</th>
      <th>0skzqs8f8h</th>
      <th>10</th>
      <th>100</th>
      <th>...</th>
      <th>yoy</th>
      <th>yuvo</th>
      <th>z4wc2sk8ji</th>
      <th>zero</th>
      <th>zoryalondonsk</th>
      <th>zwsyhywsgy</th>
      <th>𝗥𝗮𝗺𝗯𝗹𝗲𝗿</th>
      <th>𝗥𝗼𝘂𝗻𝗱𝘁𝗮𝗯𝗹𝗲</th>
      <th>𝗧𝗵𝗲</th>
      <th>label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>Aetna</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>Aetna</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>Aetna</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>Aetna</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>Aetna</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 2162 columns</p>
</div>
</div>
</div>
<p>Keep working on the vectorized data frame, I summed up the value for each column and sorted them in descending order. By doing this, we are able to get the word frequency in a more intuitive way.</p>
<div class="cell" data-execution_count="12">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>sum_words <span class="op">=</span> Xs.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">0</span>) </span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>words_freq <span class="op">=</span> [[word, sum_words[<span class="dv">0</span>, idx]] <span class="cf">for</span> word, idx <span class="kw">in</span> vectorizer.vocabulary_.items()]</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>words_freq <span class="op">=</span><span class="bu">sorted</span>(words_freq, key <span class="op">=</span> <span class="kw">lambda</span> x: x[<span class="dv">1</span>], reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>words_freq_df <span class="op">=</span> pd.DataFrame(words_freq,columns<span class="op">=</span>[<span class="st">'word'</span>,<span class="st">'Frequency'</span>])</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>words_freq_df.head(<span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="48">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>word</th>
      <th>Frequency</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>co</td>
      <td>146</td>
    </tr>
    <tr>
      <th>1</th>
      <td>cigna</td>
      <td>81</td>
    </tr>
    <tr>
      <th>2</th>
      <td>aetna</td>
      <td>77</td>
    </tr>
    <tr>
      <th>3</th>
      <td>anthem</td>
      <td>53</td>
    </tr>
    <tr>
      <th>4</th>
      <td>unitedhealth</td>
      <td>49</td>
    </tr>
    <tr>
      <th>5</th>
      <td>health</td>
      <td>40</td>
    </tr>
    <tr>
      <th>6</th>
      <td>get</td>
      <td>29</td>
    </tr>
    <tr>
      <th>7</th>
      <td>group</td>
      <td>29</td>
    </tr>
    <tr>
      <th>8</th>
      <td>amp</td>
      <td>28</td>
    </tr>
    <tr>
      <th>9</th>
      <td>plan</td>
      <td>27</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<!-- -->

</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb14" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="an">jupyter:</span><span class="co"> python3</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Text Data Cleaning"</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "11/29/2022"</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="an">pdf-engine:</span><span class="co"> lualatex</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="co">    theme : Minty</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="co">    toc: true</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="co">    code-tools: true</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a><span class="co">    code-fold: true</span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a><span class="co">    code-summary: "Code"</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a><span class="co">    toc-title: Contents</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a><span class="an">execute:</span></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a><span class="co">    warning: false</span></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk<span class="op">;</span></span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> CountVectorizer</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.corpus <span class="im">import</span> wordnet</span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.tokenize <span class="im">import</span> word_tokenize</span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.stem <span class="im">import</span> WordNetLemmatizer</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.stem <span class="im">import</span> PorterStemmer</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.corpus <span class="im">import</span> stopwords</span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> string </span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.sentiment <span class="im">import</span> SentimentIntensityAnalyzer</span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os, json</span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> glob</span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.corpus <span class="im">import</span> wordnet <span class="im">as</span> wn</span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-40"><a href="#cb14-40" aria-hidden="true" tabindex="-1"></a><span class="fu">### Introduction</span></span>
<span id="cb14-41"><a href="#cb14-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-42"><a href="#cb14-42" aria-hidden="true" tabindex="-1"></a>This page will show you how I cleaned up the text data that I gathered from Twitter API. The cleaning of text data is very different from that of record data. The goal of text data cleanup is to make raw text standardized and uniform in format for later analysis. The text data to be cleaned on this page is gathered from Twitter API. So each unit in the data is a tweet posted by the user.</span>
<span id="cb14-43"><a href="#cb14-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-44"><a href="#cb14-44" aria-hidden="true" tabindex="-1"></a><span class="fu">### Read in the Json files</span></span>
<span id="cb14-45"><a href="#cb14-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-46"><a href="#cb14-46" aria-hidden="true" tabindex="-1"></a>The first step is to read the JSON file that needs to be cleaned and open it with the pd.read_json() function. One good thing about the pd.read_json() function is that every JSON file opened with it automatically converts to a data frame which is more operable. I assigned the file to 'health_insurance_df'. I created an 'ID' column that takes the value from 1 to the length of the data frame for later use. After adding the 'ID' column, we can see that the data frame consists of 6 columns, we are going to focus on the 'text' column for cleaning purpose.</span>
<span id="cb14-47"><a href="#cb14-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-50"><a href="#cb14-50" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb14-51"><a href="#cb14-51" aria-hidden="true" tabindex="-1"></a><span class="co">#path_to_json = '/Users/liumingqian/anly-501-project-liumingqian0511/data/00-raw-data/twitter_data/'</span></span>
<span id="cb14-52"><a href="#cb14-52" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> readFiles(path):</span>
<span id="cb14-53"><a href="#cb14-53" aria-hidden="true" tabindex="-1"></a>    json_pattern <span class="op">=</span> os.path.join(path,<span class="st">'*.json'</span>)</span>
<span id="cb14-54"><a href="#cb14-54" aria-hidden="true" tabindex="-1"></a>    file_list <span class="op">=</span> glob.glob(json_pattern)</span>
<span id="cb14-55"><a href="#cb14-55" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> pd.read_json(file_list[<span class="dv">0</span>]) <span class="co"># an empty list to store the data frames</span></span>
<span id="cb14-56"><a href="#cb14-56" aria-hidden="true" tabindex="-1"></a>    <span class="co">#print(df.head())</span></span>
<span id="cb14-57"><a href="#cb14-57" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> <span class="bu">file</span> <span class="kw">in</span> file_list[<span class="dv">1</span>:]:</span>
<span id="cb14-58"><a href="#cb14-58" aria-hidden="true" tabindex="-1"></a>        data <span class="op">=</span> pd.read_json(<span class="bu">file</span>) <span class="co"># read data frame from json file</span></span>
<span id="cb14-59"><a href="#cb14-59" aria-hidden="true" tabindex="-1"></a>        <span class="co">#print(data.head())</span></span>
<span id="cb14-60"><a href="#cb14-60" aria-hidden="true" tabindex="-1"></a>        df <span class="op">=</span> pd.concat([df,data],axis<span class="op">=</span><span class="dv">0</span>, ignore_index<span class="op">=</span><span class="va">True</span>) <span class="co"># append the data frame to the list</span></span>
<span id="cb14-61"><a href="#cb14-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-62"><a href="#cb14-62" aria-hidden="true" tabindex="-1"></a>    <span class="co">#df = pd.concat(dfs,sort=False) # concatenate all the data frames in the list.</span></span>
<span id="cb14-63"><a href="#cb14-63" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df</span>
<span id="cb14-64"><a href="#cb14-64" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> readFiles(<span class="st">'/Users/liumingqian/anly-501-project-liumingqian0511/data/00-raw-data/insurance_co'</span>)</span>
<span id="cb14-65"><a href="#cb14-65" aria-hidden="true" tabindex="-1"></a>df.drop_duplicates(subset <span class="op">=</span> <span class="st">'text'</span>, inplace <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb14-66"><a href="#cb14-66" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-67"><a href="#cb14-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-70"><a href="#cb14-70" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb14-71"><a href="#cb14-71" aria-hidden="true" tabindex="-1"></a>df1 <span class="op">=</span> pd.read_json(<span class="st">'/Users/liumingqian/anly-501-project-liumingqian0511/data/00-raw-data/insurance_co/Aetna.json'</span>)</span>
<span id="cb14-72"><a href="#cb14-72" aria-hidden="true" tabindex="-1"></a>df2 <span class="op">=</span> pd.read_json(<span class="st">'/Users/liumingqian/anly-501-project-liumingqian0511/data/00-raw-data/insurance_co/Anthem.json'</span>)</span>
<span id="cb14-73"><a href="#cb14-73" aria-hidden="true" tabindex="-1"></a>df3 <span class="op">=</span> pd.read_json(<span class="st">'/Users/liumingqian/anly-501-project-liumingqian0511/data/00-raw-data/insurance_co/Cigna.json'</span>)</span>
<span id="cb14-74"><a href="#cb14-74" aria-hidden="true" tabindex="-1"></a>df4 <span class="op">=</span> pd.read_json(<span class="st">'/Users/liumingqian/anly-501-project-liumingqian0511/data/00-raw-data/insurance_co/Humana.json'</span>)</span>
<span id="cb14-75"><a href="#cb14-75" aria-hidden="true" tabindex="-1"></a>df5 <span class="op">=</span> pd.read_json(<span class="st">'/Users/liumingqian/anly-501-project-liumingqian0511/data/00-raw-data/insurance_co/UnitedHealth.json'</span>)</span>
<span id="cb14-76"><a href="#cb14-76" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-77"><a href="#cb14-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-78"><a href="#cb14-78" aria-hidden="true" tabindex="-1"></a><span class="fu">### Assign Labels Manually</span></span>
<span id="cb14-79"><a href="#cb14-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-82"><a href="#cb14-82" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb14-83"><a href="#cb14-83" aria-hidden="true" tabindex="-1"></a>df1[<span class="st">'label'</span>] <span class="op">=</span> <span class="st">'Aetna'</span></span>
<span id="cb14-84"><a href="#cb14-84" aria-hidden="true" tabindex="-1"></a>df2[<span class="st">'label'</span>] <span class="op">=</span> <span class="st">'Anthem'</span></span>
<span id="cb14-85"><a href="#cb14-85" aria-hidden="true" tabindex="-1"></a>df3[<span class="st">'label'</span>] <span class="op">=</span> <span class="st">'Cigna'</span></span>
<span id="cb14-86"><a href="#cb14-86" aria-hidden="true" tabindex="-1"></a>df4[<span class="st">'label'</span>] <span class="op">=</span> <span class="st">'Humana'</span></span>
<span id="cb14-87"><a href="#cb14-87" aria-hidden="true" tabindex="-1"></a>df5[<span class="st">'label'</span>] <span class="op">=</span> <span class="st">'UnitedHealth'</span></span>
<span id="cb14-88"><a href="#cb14-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-89"><a href="#cb14-89" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.concat([df1,df2,df3,df4,df5],ignore_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb14-90"><a href="#cb14-90" aria-hidden="true" tabindex="-1"></a>df.drop_duplicates(subset<span class="op">=</span><span class="st">'text'</span>,inplace <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb14-91"><a href="#cb14-91" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df[df[<span class="st">'lang'</span>] <span class="op">==</span> <span class="st">'en'</span>]</span>
<span id="cb14-92"><a href="#cb14-92" aria-hidden="true" tabindex="-1"></a>df.shape</span>
<span id="cb14-93"><a href="#cb14-93" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-94"><a href="#cb14-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-95"><a href="#cb14-95" aria-hidden="true" tabindex="-1"></a><span class="fu">### Sentiment Analysis</span></span>
<span id="cb14-96"><a href="#cb14-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-97"><a href="#cb14-97" aria-hidden="true" tabindex="-1"></a>The next step of text data cleaning is to perform sentiment analysis for each tweet and store the outcome of each tweet as its label. Sentiment analysis is a technique that detects the underlying sentiment in a piece of text. It is the process of classifying text as either positive, negative, or neutral. Sentiment analysis is very essential to gauge customers’ or users’ responses. In the following chunks, I wrote a getSentiments() function to rate each tweet’s sentiment scores in positivity, negativity, and neutrality. I converted the result from the dictionary to a data frame 'score', and also added a column 'ID' that takes the same value as the 'ID' column in the health_insurance_df. Displaying the first ten rows of the score data frame, we can see that we have four columns of values to rate the corresponding sentiment and one column of 'ID' for later use.</span>
<span id="cb14-98"><a href="#cb14-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-101"><a href="#cb14-101" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb14-102"><a href="#cb14-102" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> getSentiments(df):</span>
<span id="cb14-103"><a href="#cb14-103" aria-hidden="true" tabindex="-1"></a>    sia <span class="op">=</span> SentimentIntensityAnalyzer()</span>
<span id="cb14-104"><a href="#cb14-104" aria-hidden="true" tabindex="-1"></a>    tweet_str <span class="op">=</span> <span class="st">""</span></span>
<span id="cb14-105"><a href="#cb14-105" aria-hidden="true" tabindex="-1"></a>    tweetscore <span class="op">=</span> []</span>
<span id="cb14-106"><a href="#cb14-106" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> tweet <span class="kw">in</span> df[<span class="st">'text'</span>]:</span>
<span id="cb14-107"><a href="#cb14-107" aria-hidden="true" tabindex="-1"></a>        tweet_str <span class="op">=</span> tweet_str <span class="op">+</span> <span class="st">" "</span> <span class="op">+</span> tweet</span>
<span id="cb14-108"><a href="#cb14-108" aria-hidden="true" tabindex="-1"></a>        score <span class="op">=</span> sia.polarity_scores(tweet_str)</span>
<span id="cb14-109"><a href="#cb14-109" aria-hidden="true" tabindex="-1"></a>        tweetscore.append(score)</span>
<span id="cb14-110"><a href="#cb14-110" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tweetscore</span>
<span id="cb14-111"><a href="#cb14-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-112"><a href="#cb14-112" aria-hidden="true" tabindex="-1"></a>sentiment <span class="op">=</span> getSentiments(df)</span>
<span id="cb14-113"><a href="#cb14-113" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> pd.DataFrame.from_dict(sentiment)</span>
<span id="cb14-114"><a href="#cb14-114" aria-hidden="true" tabindex="-1"></a>score <span class="op">=</span> score.assign(ID <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">1</span>,<span class="bu">len</span>(score)<span class="op">+</span><span class="dv">1</span>)))</span>
<span id="cb14-115"><a href="#cb14-115" aria-hidden="true" tabindex="-1"></a>score.head(<span class="dv">10</span>)</span>
<span id="cb14-116"><a href="#cb14-116" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-117"><a href="#cb14-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-120"><a href="#cb14-120" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb14-121"><a href="#cb14-121" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.assign(ID <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">1</span>,<span class="bu">len</span>(df)<span class="op">+</span><span class="dv">1</span>)))</span>
<span id="cb14-122"><a href="#cb14-122" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.merge(score,how<span class="op">=</span><span class="st">'inner'</span>)</span>
<span id="cb14-123"><a href="#cb14-123" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'sentiment'</span>] <span class="op">=</span>df[[<span class="st">'neg'</span>,<span class="st">'neu'</span>,<span class="st">'pos'</span>]].idxmax(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb14-124"><a href="#cb14-124" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'sent_binary'</span>] <span class="op">=</span> df[[<span class="st">'neg'</span>,<span class="st">'pos'</span>]].idxmax(axis <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb14-125"><a href="#cb14-125" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-126"><a href="#cb14-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-127"><a href="#cb14-127" aria-hidden="true" tabindex="-1"></a><span class="fu">### Filter Stopwords</span></span>
<span id="cb14-128"><a href="#cb14-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-129"><a href="#cb14-129" aria-hidden="true" tabindex="-1"></a>Next, I am going to remove the stop words from the text. Stopwords are words which does not add much meaning to a sentence. They can safely be ignored without sacrificing the meaning of the sentence. For example, the words like the, I, it, etc. Such words are already captured in a corpus named corpus. We first download it to our python environment. I wrote a define function to loop through each tweet and to filter out stopwords and lowercase all the letters. Applying this function to our data frame, we can see that the 'text' column is now stopwords-free. </span>
<span id="cb14-130"><a href="#cb14-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-133"><a href="#cb14-133" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb14-134"><a href="#cb14-134" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> filterStopwords(df):</span>
<span id="cb14-135"><a href="#cb14-135" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> val, tweet <span class="kw">in</span> <span class="bu">enumerate</span>(df[<span class="st">'text'</span>]):</span>
<span id="cb14-136"><a href="#cb14-136" aria-hidden="true" tabindex="-1"></a>        new_text<span class="op">=</span><span class="st">""</span></span>
<span id="cb14-137"><a href="#cb14-137" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> word <span class="kw">in</span> nltk.tokenize.word_tokenize(tweet):</span>
<span id="cb14-138"><a href="#cb14-138" aria-hidden="true" tabindex="-1"></a>            word <span class="op">=</span> word.lower()</span>
<span id="cb14-139"><a href="#cb14-139" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> word <span class="kw">not</span> <span class="kw">in</span> nltk.corpus.stopwords.words(<span class="st">'english'</span>) <span class="kw">and</span> word <span class="kw">not</span> <span class="kw">in</span> [<span class="st">"."</span>,<span class="st">","</span>,<span class="st">"!"</span>,<span class="st">"?"</span>,<span class="st">":"</span>,<span class="st">";"</span>,<span class="st">")"</span>,<span class="st">"("</span>,<span class="st">"'"</span>,<span class="st">"$"</span>,<span class="st">'https'</span>,<span class="st">'co'</span>,<span class="st">'rt'</span>,<span class="st">'@'</span>,<span class="st">'de'</span>,<span class="st">'la'</span>,<span class="st">'the'</span>]:</span>
<span id="cb14-140"><a href="#cb14-140" aria-hidden="true" tabindex="-1"></a>                    new_text<span class="op">+=</span>word<span class="op">+</span><span class="st">" "</span></span>
<span id="cb14-141"><a href="#cb14-141" aria-hidden="true" tabindex="-1"></a>            df[<span class="st">'text'</span>][val] <span class="op">=</span> new_text</span>
<span id="cb14-142"><a href="#cb14-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-143"><a href="#cb14-143" aria-hidden="true" tabindex="-1"></a>filterStopwords(df)</span>
<span id="cb14-144"><a href="#cb14-144" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-145"><a href="#cb14-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-146"><a href="#cb14-146" aria-hidden="true" tabindex="-1"></a><span class="fu">### Lemmatization</span></span>
<span id="cb14-147"><a href="#cb14-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-150"><a href="#cb14-150" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb14-151"><a href="#cb14-151" aria-hidden="true" tabindex="-1"></a>lemmatizer <span class="op">=</span> WordNetLemmatizer()</span>
<span id="cb14-152"><a href="#cb14-152" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> lemmatize(df):</span>
<span id="cb14-153"><a href="#cb14-153" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i,tweet <span class="kw">in</span> <span class="bu">enumerate</span>(df[<span class="st">'text'</span>]):</span>
<span id="cb14-154"><a href="#cb14-154" aria-hidden="true" tabindex="-1"></a>        new_text <span class="op">=</span> <span class="st">""</span></span>
<span id="cb14-155"><a href="#cb14-155" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> word <span class="kw">in</span> tweet.split(<span class="st">' '</span>):</span>
<span id="cb14-156"><a href="#cb14-156" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> wn.synsets(word):</span>
<span id="cb14-157"><a href="#cb14-157" aria-hidden="true" tabindex="-1"></a>                new_text <span class="op">+=</span> lemmatizer.lemmatize(word,pos<span class="op">=</span> wn.synsets(word)[<span class="dv">0</span>].pos()) <span class="op">+</span> <span class="st">" "</span></span>
<span id="cb14-158"><a href="#cb14-158" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb14-159"><a href="#cb14-159" aria-hidden="true" tabindex="-1"></a>                new_text <span class="op">+=</span> word <span class="op">+</span> <span class="st">" "</span></span>
<span id="cb14-160"><a href="#cb14-160" aria-hidden="true" tabindex="-1"></a>        df[<span class="st">'text'</span>][i] <span class="op">=</span> new_text</span>
<span id="cb14-161"><a href="#cb14-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-162"><a href="#cb14-162" aria-hidden="true" tabindex="-1"></a>lemmatize(df)</span>
<span id="cb14-163"><a href="#cb14-163" aria-hidden="true" tabindex="-1"></a>df.head()</span>
<span id="cb14-164"><a href="#cb14-164" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-165"><a href="#cb14-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-166"><a href="#cb14-166" aria-hidden="true" tabindex="-1"></a><span class="fu">### Tidy Dataframe</span></span>
<span id="cb14-167"><a href="#cb14-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-168"><a href="#cb14-168" aria-hidden="true" tabindex="-1"></a>After inner joining the score data with the health_insurance_df data so that each tweet in the health_insurance data frame will have corresponding sentiment scores, the basic Text cleaning was done. Now we're going to finish up our data frame by renaming columns to more intuitive names, casting the data type, and adding a column to display the label of the tweet sentiment.</span>
<span id="cb14-169"><a href="#cb14-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-172"><a href="#cb14-172" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb14-173"><a href="#cb14-173" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'created_at'</span>] <span class="op">=</span> df[<span class="st">'created_at'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x.date)</span>
<span id="cb14-174"><a href="#cb14-174" aria-hidden="true" tabindex="-1"></a>df.rename(columns<span class="op">=</span>{<span class="st">'created_at'</span>:<span class="st">'date'</span>,<span class="st">'lang'</span>:<span class="st">'language'</span>},inplace <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb14-175"><a href="#cb14-175" aria-hidden="true" tabindex="-1"></a>df.drop(columns <span class="op">=</span> [<span class="st">'author_id'</span>,<span class="st">'id'</span>,<span class="st">'edit_history_tweet_ids'</span>,<span class="st">'neg'</span>,<span class="st">'pos'</span>,<span class="st">'neu'</span>,<span class="st">'compound'</span>],inplace <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb14-176"><a href="#cb14-176" aria-hidden="true" tabindex="-1"></a>df.head()</span>
<span id="cb14-177"><a href="#cb14-177" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-178"><a href="#cb14-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-179"><a href="#cb14-179" aria-hidden="true" tabindex="-1"></a><span class="fu">### Vectorization</span></span>
<span id="cb14-180"><a href="#cb14-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-181"><a href="#cb14-181" aria-hidden="true" tabindex="-1"></a>In programming, a vector is a data structure that is similar to a list or an array. For the purpose of an input representation, it is simply a succession of values, with the number of values representing the vector’s “dimensionality.” Text Vectorization is the process of converting text into a numerical representation. I extracted the text from each tweet and save them both to a string for word cloud and to a list for vectorizing. Using the CountVectorizer() function from the sklearn library, we can convert the corpus to a dense matrix. I transformed the matrix to a data frame in which each column takes a word. This gives us a 300 x 1026 huge data frame.</span>
<span id="cb14-182"><a href="#cb14-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-185"><a href="#cb14-185" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb14-186"><a href="#cb14-186" aria-hidden="true" tabindex="-1"></a>corpus_str <span class="op">=</span> <span class="st">""</span></span>
<span id="cb14-187"><a href="#cb14-187" aria-hidden="true" tabindex="-1"></a>corpus <span class="op">=</span> []</span>
<span id="cb14-188"><a href="#cb14-188" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'text'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: corpus.append(x))</span>
<span id="cb14-189"><a href="#cb14-189" aria-hidden="true" tabindex="-1"></a>corpus_str <span class="op">=</span> corpus_str.join(corpus)</span>
<span id="cb14-190"><a href="#cb14-190" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-191"><a href="#cb14-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-194"><a href="#cb14-194" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb14-195"><a href="#cb14-195" aria-hidden="true" tabindex="-1"></a>vectorizer<span class="op">=</span>CountVectorizer()</span>
<span id="cb14-196"><a href="#cb14-196" aria-hidden="true" tabindex="-1"></a>Xs  <span class="op">=</span>  vectorizer.fit_transform(corpus)</span>
<span id="cb14-197"><a href="#cb14-197" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.array(Xs.todense())</span>
<span id="cb14-198"><a href="#cb14-198" aria-hidden="true" tabindex="-1"></a>col_names<span class="op">=</span>vectorizer.get_feature_names_out()</span>
<span id="cb14-199"><a href="#cb14-199" aria-hidden="true" tabindex="-1"></a>vec <span class="op">=</span> pd.DataFrame(X,columns<span class="op">=</span>col_names)</span>
<span id="cb14-200"><a href="#cb14-200" aria-hidden="true" tabindex="-1"></a>vec[<span class="st">'label'</span>] <span class="op">=</span> df[<span class="st">'label'</span>]</span>
<span id="cb14-201"><a href="#cb14-201" aria-hidden="true" tabindex="-1"></a>vec.to_csv(<span class="st">'/Users/liumingqian/anly-501-project-liumingqian0511/data/01-modified-data/vec.csv'</span>)</span>
<span id="cb14-202"><a href="#cb14-202" aria-hidden="true" tabindex="-1"></a>vec.head()</span>
<span id="cb14-203"><a href="#cb14-203" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb14-204"><a href="#cb14-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-205"><a href="#cb14-205" aria-hidden="true" tabindex="-1"></a>Keep working on the vectorized data frame, I summed up the value for each column and sorted them in descending order. By doing this, we are able to get the word frequency in a more intuitive way.</span>
<span id="cb14-206"><a href="#cb14-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-209"><a href="#cb14-209" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb14-210"><a href="#cb14-210" aria-hidden="true" tabindex="-1"></a>sum_words <span class="op">=</span> Xs.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">0</span>) </span>
<span id="cb14-211"><a href="#cb14-211" aria-hidden="true" tabindex="-1"></a>words_freq <span class="op">=</span> [[word, sum_words[<span class="dv">0</span>, idx]] <span class="cf">for</span> word, idx <span class="kw">in</span> vectorizer.vocabulary_.items()]</span>
<span id="cb14-212"><a href="#cb14-212" aria-hidden="true" tabindex="-1"></a>words_freq <span class="op">=</span><span class="bu">sorted</span>(words_freq, key <span class="op">=</span> <span class="kw">lambda</span> x: x[<span class="dv">1</span>], reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb14-213"><a href="#cb14-213" aria-hidden="true" tabindex="-1"></a>words_freq_df <span class="op">=</span> pd.DataFrame(words_freq,columns<span class="op">=</span>[<span class="st">'word'</span>,<span class="st">'Frequency'</span>])</span>
<span id="cb14-214"><a href="#cb14-214" aria-hidden="true" tabindex="-1"></a>words_freq_df.head(<span class="dv">10</span>)</span>
<span id="cb14-215"><a href="#cb14-215" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>