<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
  <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    <div class="container-fluid">
      <a class="navbar-brand" href="../index.html">ANLY501</a>
      <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarColor02" aria-controls="navbarColor02" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarColor02">
        <ul class="navbar-nav me-auto">
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/anly501/anly-501-project-liumingqian0511/tree/main/codes">Code</a>
          </li>
          <!-- Introduction -->
          <li class="nav-item">
            <a class="nav-link" href="./introduction00.html">Introduction</a>
          </li>
          <!-- Data Gathering -->
          <li class="nav-item">
            <a class="nav-link" href="./text_gather.html">Data Gathering</a>
          </li>
          <!-- Record Data -->
          <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle" data-bs-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">Record Data</a>
            <div class="dropdown-menu">
              <a class="dropdown-item" href="./record_data_cleaning.html">Cleaning</a>
              <a class="dropdown-item" href="./Record_Data_Exploring.html">Exploring</a>
            </div>
          </li>
          <!-- Text Data -->
          <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle" data-bs-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">Text Data</a>
            <div class="dropdown-menu">
              <a class="dropdown-item" href="./text_clean.html">Cleaning</a>
              <a class="dropdown-item" href="./text_data_explore.html">Exploring</a>
            </div>
          </li>
          <!-- NB -->
          <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle" data-bs-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">Naive Bayes</a>
            <div class="dropdown-menu">
              <a class="dropdown-item" href="./record_NB.html">Record data</a>
              <a class="dropdown-item" href="./textNB.html">Text data</a>
            </div>
          </li>
          <!-- Classification -->
          <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle" data-bs-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">Classification</a>
            <div class="dropdown-menu">
              <a class="dropdown-item" href="./decision_tree.html">Decision Tree</a>
              <a class="dropdown-item" href="./svm_text.html">SVM</a>
            </div>
          </li>
          <!-- Clustering -->
          <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Clustering</a>
            <div class="dropdown-menu">
              <a class="dropdown-item" href="./intro_cluster.html">Intro & Theory</a>
              <a class="dropdown-item" href="./Methods_page.html">Method & Result</a>
              <a class="dropdown-item" href="./Conlusion.html">Conclusion</a>
            </div>
          </li>
          <!-- ARM -->
          <li class="nav-item">
            <a class="nav-link" href="./arm.html">ARM</a>
          </li>
          <!-- Conclusion -->
          <li class="nav-item">
            <a class="nav-link" href="./conclusion00.html">Conclusion</a>
          </li>
          <!-- Data -->
          <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle" data-bs-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">Data</a>
            <div class="dropdown-menu">
              <a class="dropdown-item" href="#">Raw</a>
              <a class="dropdown-item" href="#">Modified</a>
            </div>
          </li>
        </ul>
      </div>
    </div>
  </nav>
<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.251">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2022-11-29">

<title>Naive Bayes with Text Data</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="textNB_files/libs/clipboard/clipboard.min.js"></script>
<script src="textNB_files/libs/quarto-html/quarto.js"></script>
<script src="textNB_files/libs/quarto-html/popper.min.js"></script>
<script src="textNB_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="textNB_files/libs/quarto-html/anchor.min.js"></script>
<link href="textNB_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="textNB_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="textNB_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="textNB_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="textNB_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#read-in-the-data" id="toc-read-in-the-data" class="nav-link" data-scroll-target="#read-in-the-data">Read in the Data</a></li>
  <li><a href="#training-and-testing" id="toc-training-and-testing" class="nav-link" data-scroll-target="#training-and-testing">Training and Testing</a></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Naive Bayes with Text Data</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">November 29, 2022</p>
    </div>
  </div>
    
  </div>
  

</header>

<section id="introduction" class="level3">
<h3 class="anchored" data-anchor-id="introduction">Introduction</h3>
<p>In this section, we are going to classify the data sets using the Naive Bayes classifier. The purpose of classification is to separate and organize data into relevant groups ('classes') based on their shared characteristics. In data science, a classifier is a type of machine learning algorithm used to assign a class label to a data input. An example is an image recognition classifier to label an image (e.g., 'car', 'truck', or 'person'). Classifier algorithms are trained using labeled data; in the image recognition example, for instance, the classifier receives training data that label images. After sufficient training, the classifier then can receive unlabeled images as inputs and will output classification labels for each image.</p>
<p>There are many algorithms for data classification, naive Bayes classifier belongs to a family of simple 'probabilistic classifiers' based on applying Bayes' theorem with strong (naive) independence assumptions between the features. Before we dive into the algorithm itself, I want to review the Bayes theorem a bit with you. Bayes' Theorem is a simple mathematical formula used for calculating conditional probabilities which is a measure of the probability of an event occurring given that another event has occurred. Applying Bayes' Theorem to the classification of the data, the output will be the likelihood of an outcome to happen given specific features (input).</p>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">#LOAD RELEVANT PACKAGES</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_iris</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span>  pd</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> plot_confusion_matrix</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="read-in-the-data" class="level3">
<h3 class="anchored" data-anchor-id="read-in-the-data">Read in the Data</h3>
<p>Before applying classification on the data using Naive Bayes, it is very essential to prepare our text data in the form of a matrix where each row represents a tweet and each column represents a word. The value in the matrix will then be the number of occurrences of the corresponding word. This process of converting each text to a long vector is called vectorization, and we have performed this in the data cleaning step and created a vectorized csv file <a href="https://github.com/anly501/anly-501-project-liumingqian0511/tree/main/data/01-modified-data">here</a>. Also in the data cleaning step, I created another word frequency data frame which returns the frequency of all words in the texts in a descending order. The purpose of creating the word frequency data frame is to subsetting the vectorized text data by the top-referenced words. The threshold I chose for 'top referenced' is 170, which is smaller than the total rows of texts.</p>
<p>I gathered my text data from Twitter API, and the search words I used were five popular health insurance companies: Aetna, Anthem, Cigna, Humana, and UnitedHealth. Before merging these five separate text datasets into one big dataset, I manually assign them with labels to differentiate their belonging group. The labels that represent their topic of tweets would be the target of prediction. In other words, we are going to classify the data and train a model to predict the likelihood of a text belonging to a specific topic.</p>
<div class="cell" data-execution_count="2">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>df0 <span class="op">=</span> pd.read_csv(<span class="st">'/Users/liumingqian/anly-501-project-liumingqian0511/data/01-modified-data/vec.csv'</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>wf <span class="op">=</span> pd.read_csv(<span class="st">'/Users/liumingqian/anly-501-project-liumingqian0511/data/01-modified-data/word_frequency_text.csv'</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df0[wf[<span class="st">'word'</span>][:<span class="dv">170</span>]]</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df.head(<span class="dv">10</span>))</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>conditions <span class="op">=</span> [</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    (df0[<span class="st">'label'</span>] <span class="op">==</span> <span class="st">'Aetna'</span>),</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    (df0[<span class="st">'label'</span>] <span class="op">==</span> <span class="st">'Anthem'</span>),</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    (df0[<span class="st">'label'</span>] <span class="op">==</span> <span class="st">'Cigna'</span>),</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    (df0[<span class="st">'label'</span>] <span class="op">==</span> <span class="st">'Humana'</span>),</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    (df0[<span class="st">'label'</span>] <span class="op">==</span> <span class="st">'UnitedHealth'</span>)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="co"># create a list of the values we want to assign for each condition</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>values <span class="op">=</span> [<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>]</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>label <span class="op">=</span> np.select(conditions, values)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>   co  cigna  aetna  anthem  unitedhealth  health  get  group  amp  plan  ...  \
0   0      0      1       0             0       0    0      0    0     0  ...   
1   0      0      1       0             0       0    0      0    0     0  ...   
2   0      0      1       0             0       1    0      0    0     1  ...   
3   0      0      1       0             0       0    0      0    0     0  ...   
4   0      0      1       0             0       0    1      0    0     1  ...   
5   0      0      2       0             0       0    0      0    0     0  ...   
6   0      0      1       0             0       0    0      0    0     0  ...   
7   1      1      1       0             0       1    0      0    1     1  ...   
8   1      0      1       0             0       0    0      0    0     0  ...   
9   0      0      1       0             0       0    0      1    0     0  ...   

   urban  annual  award  social  and  part  arthritisstl  going  online  even  
0      0       0      0       0    0     0             0      0       0     0  
1      0       0      0       0    0     0             0      0       0     0  
2      0       0      0       0    0     0             0      0       0     0  
3      0       0      0       0    0     0             0      0       0     0  
4      0       0      0       0    0     0             0      0       0     0  
5      0       0      0       0    0     0             0      0       0     0  
6      0       0      0       0    0     0             0      0       0     0  
7      0       0      0       0    0     0             0      0       0     0  
8      0       0      0       0    0     0             0      0       0     0  
9      0       0      0       0    0     0             0      0       0     0  

[10 rows x 170 columns]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="3">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>u <span class="op">=</span> np.mean(df,axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>sd <span class="op">=</span>np.std(df, axis <span class="op">=</span> <span class="dv">0</span>) </span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    df.iloc[:,i] <span class="op">=</span> (df.iloc[:,i] <span class="op">-</span> u[i])<span class="op">/</span>sd[i]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Separating data into training and testing sets is an important part of evaluating data mining models. Typically, when you separate a data set into a training set and testing set, most of the data is used for training, and a smaller portion of the data is used for testing. The purpose of splitting the data into two sets is for validating the model that we train. After a model has been processed by using the training set, we test the model by making predictions against the test set. Because the data in the testing set already contains known values for the attribute that you want to predict, it is easy to determine whether the model's guesses are correct. If the model we fitted using training data can precisely predict the result of testing, then we can validate that the model is good. Using the <strong>sklearn.model_selection</strong> package, I split the data into x_train, x_test, y_train and y_test with the ratio 0.2 between the train and test. I am going to use x_train and y_train to train the model and apply it on x_test and y_test for validation.</p>
<div class="cell" data-execution_count="4">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co">#INSERT CODE TO PARTITION DATASET INTO TRAINING-</span><span class="al">TEST</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.to_numpy()</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> label</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>test_ratio<span class="op">=</span><span class="fl">0.2</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>x_train, x_test, y_train, y_test <span class="op">=</span> train_test_split(X, Y, test_size<span class="op">=</span>test_ratio, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co">#y_train=y_train.flatten()</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co">#y_test=y_test.flatten()</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x_train.shape        :"</span>,x_train.shape)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"y_train.shape        :"</span>,y_train.shape)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"X_test.shape     :"</span>,x_test.shape)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"y_test.shape     :"</span>,y_test.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>x_train.shape       : (215, 170)
y_train.shape       : (215,)
X_test.shape        : (54, 170)
y_test.shape        : (54,)</code></pre>
</div>
</div>
</section>
<section id="training-and-testing" class="level3">
<h3 class="anchored" data-anchor-id="training-and-testing">Training and Testing</h3>
<p>Still using the sklearn package, the outcome is printed below. The accuracy of 96% in the training set is considered very high, only 7 texts were mislabeled out of the total 215 texts in the training set. However, high accuracy in the training set is not enough to validate the model since the model itself is trained using this set. We can see from the result that the accuracy of the testing set drops to 65%. It is not a bad outcome considering we have 5 classes as the target. This number means that when we use the Gaussian Naive Bayes model that we trained from the training sets to predict the outcome of the testing set, the likelihood of the prediction being accurate is 65%.</p>
<p>To interpret the confusion matrix generated by using the sklearn package, we just need to focus on the diagonal of the matrix which represents the accurate cases when we successfully predicted the outcome. The more yellowish, the higher accuracy of the prediction is. As shown in the confusion matrix plots below, we can see that the diagonal of the confusion matrix in the training set is a lot brighter than in the testing set. But overall in both matrices, the diagonal is brighter than the other squares which means that there are a lot more accurate cases than inaccurate ones.</p>
<div class="cell" data-execution_count="5">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.naive_bayes <span class="im">import</span> GaussianNB</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> GaussianNB()</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> clf.fit(x_train, y_train)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="co">#INSERT CODE TO PRINT THE ACCURACY AND NUMBER OF MISLABELED POINTS  FOR BOTH TRAINING AND </span><span class="al">TEST</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'ACCURACY CALCULATION'</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'TRAINING SET:'</span>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Accuracy:'</span>, model.score(x_train,y_train))</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Number of mislabeled points out of a total 215 points = '</span>,(y_train <span class="op">!=</span>model.predict(x_train)).<span class="bu">sum</span>())</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">' '</span>)</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'TEST SET:'</span>)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Accuracy:'</span>, model.score(x_test,y_test))</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Number of mislabeled points out of a total 54 points = '</span>,(y_test <span class="op">!=</span>model.predict(x_test)).<span class="bu">sum</span>())</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">' '</span>)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'CHECK FIRST 20 PREDICTIONS'</span>)</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'TRAINING SET:'</span>)</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(y_train[<span class="dv">0</span>:<span class="dv">20</span>])</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model.predict(x_train)[<span class="dv">0</span>:<span class="dv">20</span>])</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'ERROR'</span>, model.predict(x_train)[<span class="dv">0</span>:<span class="dv">20</span>]<span class="op">-</span>y_train[<span class="dv">0</span>:<span class="dv">20</span>])</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">' '</span>)</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'TEST SET:'</span>)</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(y_test[<span class="dv">0</span>:<span class="dv">20</span>])</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model.predict(x_test)[<span class="dv">0</span>:<span class="dv">20</span>])</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'ERROR'</span>, model.predict(x_test)[<span class="dv">0</span>:<span class="dv">20</span>]<span class="op">-</span>y_test[<span class="dv">0</span>:<span class="dv">20</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>ACCURACY CALCULATION
TRAINING SET:</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy: 0.9674418604651163
Number of mislabeled points out of a total 215 points =  7
 
TEST SET:
Accuracy: 0.6481481481481481
Number of mislabeled points out of a total 54 points =  19
 
CHECK FIRST 20 PREDICTIONS
TRAINING SET:
[5 1 5 5 3 2 2 1 3 2 1 3 2 2 2 3 1 3 3 5]
[5 1 5 5 3 2 2 1 3 2 1 2 2 2 2 3 1 3 3 5]
ERROR [ 0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0  0  0]
 
TEST SET:
[5 5 2 3 3 2 3 3 1 1 2 5 2 3 3 5 3 3 2 1]
[1 5 2 1 3 2 5 3 1 5 2 5 1 1 3 5 3 1 2 1]
ERROR [-4  0  0 -2  0  0  2  0  0  4  0  0 -1 -2  0  0  0 -2  0  0]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="6">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>plot_confusion_matrix(clf, x_test, y_test)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>plot_confusion_matrix(clf, x_train, y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>&lt;sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fbdb49eda20&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="textNB_files/figure-html/cell-7-output-2.png" width="496" height="434"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="textNB_files/figure-html/cell-7-output-3.png" width="496" height="434"></p>
</div>
</div>
<!-- -->

</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb12" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="an">jupyter:</span><span class="co"> python3</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Naive Bayes with Text Data"</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "11/29/2022"</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="an">pdf-engine:</span><span class="co"> lualatex</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="co">    theme : Minty</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="co">    toc: true</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a><span class="co">    code-tools: true</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="co">    code-fold: true</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a><span class="co">    code-summary: "Code"</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a><span class="co">    toc-title: Contents</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a><span class="an">execute:</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a><span class="co">    warning: false</span></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a><span class="fu">### Introduction</span></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>In this section, we are going to classify the data sets using the Naive Bayes classifier. The purpose of classification is to separate and organize data into relevant groups (“classes”) based on their shared characteristics. In data science, a classifier is a type of machine learning algorithm used to assign a class label to a data input. An example is an image recognition classifier to label an image (e.g., “car,” “truck,” or “person”). Classifier algorithms are trained using labeled data; in the image recognition example, for instance, the classifier receives training data that label images. After sufficient training, the classifier then can receive unlabeled images as inputs and will output classification labels for each image.</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>There are many algorithms for data classification, naive Bayes classifier belongs to a family of simple "probabilistic classifiers" based on applying Bayes' theorem with strong (naive) independence assumptions between the features. Before we dive into the algorithm itself, I want to review the Bayes theorem a bit with you. Bayes' Theorem is a simple mathematical formula used for calculating conditional probabilities which is a measure of the probability of an event occurring given that another event has occurred. Applying Bayes' Theorem to the classification of the data, the output will be the likelihood of an outcome to happen given specific features (input).</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a><span class="co">#LOAD RELEVANT PACKAGES</span></span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> load_iris</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span>  pd</span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> plot_confusion_matrix</span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a><span class="fu">### Read in the Data</span></span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a>Before applying classification on the data using Naive Bayes, it is very essential to prepare our text data in the form of a matrix where each row represents a tweet and each column represents a word. The value in the matrix will then be the number of occurrences of the corresponding word. This process of converting each text to a long vector is called vectorization, and we have performed this in the data cleaning step and created a vectorized csv file <span class="co">[</span><span class="ot">here</span><span class="co">](https://github.com/anly501/anly-501-project-liumingqian0511/tree/main/data/01-modified-data)</span>. Also in the data cleaning step, I created another word frequency data frame which returns the frequency of all words in the texts in a descending order. The purpose of creating the word frequency data frame is to subsetting the vectorized text data by the top-referenced words. The threshold I chose for 'top referenced' is 170, which is smaller than the total rows of texts.</span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-42"><a href="#cb12-42" aria-hidden="true" tabindex="-1"></a>I gathered my text data from Twitter API, and the search words I used were five popular health insurance companies: Aetna, Anthem, Cigna, Humana, and UnitedHealth. Before merging these five separate text datasets into one big dataset, I manually assign them with labels to differentiate their belonging group. The labels that represent their topic of tweets would be the target of prediction. In other words, we are going to classify the data and train a model to predict the likelihood of a text belonging to a specific topic.</span>
<span id="cb12-43"><a href="#cb12-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-44"><a href="#cb12-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-47"><a href="#cb12-47" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb12-48"><a href="#cb12-48" aria-hidden="true" tabindex="-1"></a>df0 <span class="op">=</span> pd.read_csv(<span class="st">'/Users/liumingqian/anly-501-project-liumingqian0511/data/01-modified-data/vec.csv'</span>)</span>
<span id="cb12-49"><a href="#cb12-49" aria-hidden="true" tabindex="-1"></a>wf <span class="op">=</span> pd.read_csv(<span class="st">'/Users/liumingqian/anly-501-project-liumingqian0511/data/01-modified-data/word_frequency_text.csv'</span>)</span>
<span id="cb12-50"><a href="#cb12-50" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df0[wf[<span class="st">'word'</span>][:<span class="dv">170</span>]]</span>
<span id="cb12-51"><a href="#cb12-51" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df.head(<span class="dv">10</span>))</span>
<span id="cb12-52"><a href="#cb12-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-53"><a href="#cb12-53" aria-hidden="true" tabindex="-1"></a>conditions <span class="op">=</span> [</span>
<span id="cb12-54"><a href="#cb12-54" aria-hidden="true" tabindex="-1"></a>    (df0[<span class="st">'label'</span>] <span class="op">==</span> <span class="st">'Aetna'</span>),</span>
<span id="cb12-55"><a href="#cb12-55" aria-hidden="true" tabindex="-1"></a>    (df0[<span class="st">'label'</span>] <span class="op">==</span> <span class="st">'Anthem'</span>),</span>
<span id="cb12-56"><a href="#cb12-56" aria-hidden="true" tabindex="-1"></a>    (df0[<span class="st">'label'</span>] <span class="op">==</span> <span class="st">'Cigna'</span>),</span>
<span id="cb12-57"><a href="#cb12-57" aria-hidden="true" tabindex="-1"></a>    (df0[<span class="st">'label'</span>] <span class="op">==</span> <span class="st">'Humana'</span>),</span>
<span id="cb12-58"><a href="#cb12-58" aria-hidden="true" tabindex="-1"></a>    (df0[<span class="st">'label'</span>] <span class="op">==</span> <span class="st">'UnitedHealth'</span>)</span>
<span id="cb12-59"><a href="#cb12-59" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb12-60"><a href="#cb12-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-61"><a href="#cb12-61" aria-hidden="true" tabindex="-1"></a><span class="co"># create a list of the values we want to assign for each condition</span></span>
<span id="cb12-62"><a href="#cb12-62" aria-hidden="true" tabindex="-1"></a>values <span class="op">=</span> [<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>]</span>
<span id="cb12-63"><a href="#cb12-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-64"><a href="#cb12-64" aria-hidden="true" tabindex="-1"></a>label <span class="op">=</span> np.select(conditions, values)</span>
<span id="cb12-65"><a href="#cb12-65" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb12-66"><a href="#cb12-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-67"><a href="#cb12-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-70"><a href="#cb12-70" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb12-71"><a href="#cb12-71" aria-hidden="true" tabindex="-1"></a>u <span class="op">=</span> np.mean(df,axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb12-72"><a href="#cb12-72" aria-hidden="true" tabindex="-1"></a>sd <span class="op">=</span>np.std(df, axis <span class="op">=</span> <span class="dv">0</span>) </span>
<span id="cb12-73"><a href="#cb12-73" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>):</span>
<span id="cb12-74"><a href="#cb12-74" aria-hidden="true" tabindex="-1"></a>    df.iloc[:,i] <span class="op">=</span> (df.iloc[:,i] <span class="op">-</span> u[i])<span class="op">/</span>sd[i]</span>
<span id="cb12-75"><a href="#cb12-75" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb12-76"><a href="#cb12-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-77"><a href="#cb12-77" aria-hidden="true" tabindex="-1"></a>Separating data into training and testing sets is an important part of evaluating data mining models. Typically, when you separate a data set into a training set and testing set, most of the data is used for training, and a smaller portion of the data is used for testing. The purpose of splitting the data into two sets is for validating the model that we train. After a model has been processed by using the training set, we test the model by making predictions against the test set. Because the data in the testing set already contains known values for the attribute that you want to predict, it is easy to determine whether the model's guesses are correct. If the model we fitted using training data can precisely predict the result of testing, then we can validate that the model is good. Using the **sklearn.model_selection** package, I split the data into x_train, x_test, y_train and y_test with the ratio 0.2 between the train and test. I am going to use x_train and y_train to train the model and apply it on x_test and y_test for validation.</span>
<span id="cb12-78"><a href="#cb12-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-81"><a href="#cb12-81" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb12-82"><a href="#cb12-82" aria-hidden="true" tabindex="-1"></a><span class="co">#INSERT CODE TO PARTITION DATASET INTO TRAINING-</span><span class="al">TEST</span></span>
<span id="cb12-83"><a href="#cb12-83" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.to_numpy()</span>
<span id="cb12-84"><a href="#cb12-84" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> label</span>
<span id="cb12-85"><a href="#cb12-85" aria-hidden="true" tabindex="-1"></a>test_ratio<span class="op">=</span><span class="fl">0.2</span></span>
<span id="cb12-86"><a href="#cb12-86" aria-hidden="true" tabindex="-1"></a>x_train, x_test, y_train, y_test <span class="op">=</span> train_test_split(X, Y, test_size<span class="op">=</span>test_ratio, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb12-87"><a href="#cb12-87" aria-hidden="true" tabindex="-1"></a><span class="co">#y_train=y_train.flatten()</span></span>
<span id="cb12-88"><a href="#cb12-88" aria-hidden="true" tabindex="-1"></a><span class="co">#y_test=y_test.flatten()</span></span>
<span id="cb12-89"><a href="#cb12-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-90"><a href="#cb12-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-91"><a href="#cb12-91" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x_train.shape        :"</span>,x_train.shape)</span>
<span id="cb12-92"><a href="#cb12-92" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"y_train.shape        :"</span>,y_train.shape)</span>
<span id="cb12-93"><a href="#cb12-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-94"><a href="#cb12-94" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"X_test.shape     :"</span>,x_test.shape)</span>
<span id="cb12-95"><a href="#cb12-95" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"y_test.shape     :"</span>,y_test.shape)</span>
<span id="cb12-96"><a href="#cb12-96" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb12-97"><a href="#cb12-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-98"><a href="#cb12-98" aria-hidden="true" tabindex="-1"></a><span class="fu">### Training and Testing</span></span>
<span id="cb12-99"><a href="#cb12-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-100"><a href="#cb12-100" aria-hidden="true" tabindex="-1"></a>Still using the sklearn package, the outcome is printed below. The accuracy of 96% in the training set is considered very high, only 7 texts were mislabeled out of the total 215 texts in the training set. However, high accuracy in the training set is not enough to validate the model since the model itself is trained using this set. We can see from the result that the accuracy of the testing set drops to 65%. It is not a bad outcome considering we have 5 classes as the target. This number means that when we use the Gaussian Naive Bayes model that we trained from the training sets to predict the outcome of the testing set, the likelihood of the prediction being accurate is 65%.</span>
<span id="cb12-101"><a href="#cb12-101" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb12-102"><a href="#cb12-102" aria-hidden="true" tabindex="-1"></a>To interpret the confusion matrix generated by using the sklearn package, we just need to focus on the diagonal of the matrix which represents the accurate cases when we successfully predicted the outcome. The more yellowish, the higher accuracy of the prediction is. As shown in the confusion matrix plots below, we can see that the diagonal of the confusion matrix in the training set is a lot brighter than in the testing set. But overall in both matrices, the diagonal is brighter than the other squares which means that there are a lot more accurate cases than inaccurate ones.</span>
<span id="cb12-103"><a href="#cb12-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-106"><a href="#cb12-106" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb12-107"><a href="#cb12-107" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.naive_bayes <span class="im">import</span> GaussianNB</span>
<span id="cb12-108"><a href="#cb12-108" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> GaussianNB()</span>
<span id="cb12-109"><a href="#cb12-109" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> clf.fit(x_train, y_train)</span>
<span id="cb12-110"><a href="#cb12-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-111"><a href="#cb12-111" aria-hidden="true" tabindex="-1"></a><span class="co">#INSERT CODE TO PRINT THE ACCURACY AND NUMBER OF MISLABELED POINTS  FOR BOTH TRAINING AND </span><span class="al">TEST</span></span>
<span id="cb12-112"><a href="#cb12-112" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'ACCURACY CALCULATION'</span>)</span>
<span id="cb12-113"><a href="#cb12-113" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'TRAINING SET:'</span>)</span>
<span id="cb12-114"><a href="#cb12-114" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Accuracy:'</span>, model.score(x_train,y_train))</span>
<span id="cb12-115"><a href="#cb12-115" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Number of mislabeled points out of a total 215 points = '</span>,(y_train <span class="op">!=</span>model.predict(x_train)).<span class="bu">sum</span>())</span>
<span id="cb12-116"><a href="#cb12-116" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">' '</span>)</span>
<span id="cb12-117"><a href="#cb12-117" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'TEST SET:'</span>)</span>
<span id="cb12-118"><a href="#cb12-118" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Accuracy:'</span>, model.score(x_test,y_test))</span>
<span id="cb12-119"><a href="#cb12-119" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Number of mislabeled points out of a total 54 points = '</span>,(y_test <span class="op">!=</span>model.predict(x_test)).<span class="bu">sum</span>())</span>
<span id="cb12-120"><a href="#cb12-120" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">' '</span>)</span>
<span id="cb12-121"><a href="#cb12-121" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'CHECK FIRST 20 PREDICTIONS'</span>)</span>
<span id="cb12-122"><a href="#cb12-122" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'TRAINING SET:'</span>)</span>
<span id="cb12-123"><a href="#cb12-123" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(y_train[<span class="dv">0</span>:<span class="dv">20</span>])</span>
<span id="cb12-124"><a href="#cb12-124" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model.predict(x_train)[<span class="dv">0</span>:<span class="dv">20</span>])</span>
<span id="cb12-125"><a href="#cb12-125" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'ERROR'</span>, model.predict(x_train)[<span class="dv">0</span>:<span class="dv">20</span>]<span class="op">-</span>y_train[<span class="dv">0</span>:<span class="dv">20</span>])</span>
<span id="cb12-126"><a href="#cb12-126" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">' '</span>)</span>
<span id="cb12-127"><a href="#cb12-127" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'TEST SET:'</span>)</span>
<span id="cb12-128"><a href="#cb12-128" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(y_test[<span class="dv">0</span>:<span class="dv">20</span>])</span>
<span id="cb12-129"><a href="#cb12-129" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model.predict(x_test)[<span class="dv">0</span>:<span class="dv">20</span>])</span>
<span id="cb12-130"><a href="#cb12-130" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'ERROR'</span>, model.predict(x_test)[<span class="dv">0</span>:<span class="dv">20</span>]<span class="op">-</span>y_test[<span class="dv">0</span>:<span class="dv">20</span>])</span>
<span id="cb12-131"><a href="#cb12-131" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb12-132"><a href="#cb12-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-135"><a href="#cb12-135" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb12-136"><a href="#cb12-136" aria-hidden="true" tabindex="-1"></a>plot_confusion_matrix(clf, x_test, y_test)</span>
<span id="cb12-137"><a href="#cb12-137" aria-hidden="true" tabindex="-1"></a>plot_confusion_matrix(clf, x_train, y_train)</span>
<span id="cb12-138"><a href="#cb12-138" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>