<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
  <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    <div class="container-fluid">
      <a class="navbar-brand" href="../index.html">ANLY501</a>
      <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarColor02" aria-controls="navbarColor02" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarColor02">
        <ul class="navbar-nav me-auto">
          <li class="nav-item">
            <a class="nav-link" href="https://github.com/anly501/anly-501-project-liumingqian0511/tree/main/codes">Code</a>
          </li>
          <!-- Introduction -->
          <li class="nav-item">
            <a class="nav-link" href="./introduction00.html">Introduction</a>
          </li>
          <!-- Data Gathering -->
          <li class="nav-item">
            <a class="nav-link" href="./text_gather.html">Data Gathering</a>
          </li>
          <!-- Record Data -->
          <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle" data-bs-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">Record Data</a>
            <div class="dropdown-menu">
              <a class="dropdown-item" href="./record_data_cleaning.html">Cleaning</a>
              <a class="dropdown-item" href="./Record_Data_Exploring.html">Exploring</a>
            </div>
          </li>
          <!-- Text Data -->
          <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle" data-bs-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">Text Data</a>
            <div class="dropdown-menu">
              <a class="dropdown-item" href="./text_clean.html">Cleaning</a>
              <a class="dropdown-item" href="./text_data_explore.html">Exploring</a>
            </div>
          </li>
          <!-- NB -->
          <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle" data-bs-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">Naive Bayes</a>
            <div class="dropdown-menu">
              <a class="dropdown-item" href="./record_NB.html">Record data</a>
              <a class="dropdown-item" href="./textNB.html">Text data</a>
            </div>
          </li>
          <!-- Classification -->
          <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle" data-bs-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">Classification</a>
            <div class="dropdown-menu">
              <a class="dropdown-item" href="./decision_tree.html">Decision Tree</a>
              <a class="dropdown-item" href="./svm_text.html">SVM</a>
            </div>
          </li>
          <!-- Clustering -->
          <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Clustering</a>
            <div class="dropdown-menu">
              <a class="dropdown-item" href="./intro_cluster.html">Intro & Theory</a>
              <a class="dropdown-item" href="./Methods_page.html">Method & Result</a>
              <a class="dropdown-item" href="./Conlusion.html">Conclusion</a>
            </div>
          </li>
          <!-- ARM -->
          <li class="nav-item">
            <a class="nav-link" href="./arm.html">ARM</a>
          </li>
          <!-- Conclusion -->
          <li class="nav-item">
            <a class="nav-link" href="./conclusion00.html">Conclusion</a>
          </li>
          <!-- Data -->
          <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle" data-bs-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false">Data</a>
            <div class="dropdown-menu">
              <a class="dropdown-item" href="#">Raw</a>
              <a class="dropdown-item" href="#">Modified</a>
            </div>
          </li>
        </ul>
      </div>
    </div>
  </nav>
<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.251">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2022-10-24">

<title>SVM on Text Data</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="svm_text_files/libs/clipboard/clipboard.min.js"></script>
<script src="svm_text_files/libs/quarto-html/quarto.js"></script>
<script src="svm_text_files/libs/quarto-html/popper.min.js"></script>
<script src="svm_text_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="svm_text_files/libs/quarto-html/anchor.min.js"></script>
<link href="svm_text_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="svm_text_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="svm_text_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="svm_text_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="svm_text_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#method" id="toc-method" class="nav-link active" data-scroll-target="#method">Method</a></li>
  <li><a href="#class-distribution" id="toc-class-distribution" class="nav-link" data-scroll-target="#class-distribution">Class Distribution</a></li>
  <li><a href="#random-classifier" id="toc-random-classifier" class="nav-link" data-scroll-target="#random-classifier">Random Classifier</a></li>
  <li><a href="#feature-selection-support-vector-classifier" id="toc-feature-selection-support-vector-classifier" class="nav-link" data-scroll-target="#feature-selection-support-vector-classifier">Feature Selection: Support Vector Classifier</a></li>
  <li><a href="#hyperparameter-tuning" id="toc-hyperparameter-tuning" class="nav-link" data-scroll-target="#hyperparameter-tuning">Hyperparameter Tuning</a></li>
  <li><a href="#final-result-and-conclusion" id="toc-final-result-and-conclusion" class="nav-link" data-scroll-target="#final-result-and-conclusion">Final Result and Conclusion</a></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">SVM on Text Data</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">October 24, 2022</p>
    </div>
  </div>
    
  </div>
  

</header>

<section id="method" class="level3">
<h3 class="anchored" data-anchor-id="method">Method</h3>
<p><strong>What is Support Vector Machines?</strong></p>
<p>A support vector machine (SVM) is a supervised machine learning model that uses classification algorithms for two-group classification problems. After giving an SVM model sets of labeled training data for each category, they're able to categorize new text.</p>
<p>Compared to newer algorithms like neural networks, they have two main advantages: higher speed and better performance with a limited number of samples (in the thousands). This makes the algorithm very suitable for text classification problems, where it's common to have access to a dataset of at most a couple of thousands of tagged samples.</p>
<p><strong>How Does SVM Work?</strong></p>
<p>The basics of Support Vector Machines and how it works are best understood with a simple example. Let's imagine we have two tags: red and blue, and our data has two features: x and y. We want a classifier that, given a pair of (x,y) coordinates, outputs if it's either red or blue. We plot our already labeled training data on a plane:<br>
<img src="labeled.png" class="img-fluid" alt="Our labeled data"></p>
<p>A support vector machine takes these data points and outputs the hyperplane (which in two dimensions it's simply a line) that best separates the tags. This line is the decision boundary: anything that falls to one side of it we will classify as blue, and anything that falls to the other as red.<br>
<img src="2D.png" class="img-fluid" alt="In 2D, the best hyperplane is simply a line"></p>
<p>But, what exactly is the best hyperplane? For SVM, it's the one that maximizes the margins from both tags. In other words: the hyperplane (remember it's a line in this case) whose distance to the nearest element of each tag is the largest.</p>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, ConfusionMatrixDisplay</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> tree</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> precision_score</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> recall_score</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report, confusion_matrix</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="class-distribution" class="level2">
<h2 class="anchored" data-anchor-id="class-distribution">Class Distribution</h2>
<p>For text data, the label consists of four insurance company. I gathered the data from twitter API using the hashtags of these insurance company. Each tweet in the data belongs to a topic of hashtag. Based on the output, we can see that the distribution of labels is very balanced. Having a balanced data set for a model would generate higher accuracy models, higher balanced accuracy and balanced detection rate. Hence, its important to have a balanced data set for a classification model.</p>
<div class="cell" data-execution_count="2">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>df0 <span class="op">=</span> pd.read_csv(<span class="st">'/Users/liumingqian/anly-501-project-liumingqian0511/data/01-modified-data/vec.csv'</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>wf <span class="op">=</span> pd.read_csv(<span class="st">'/Users/liumingqian/anly-501-project-liumingqian0511/data/01-modified-data/word_frequency_text.csv'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="3">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>distribution <span class="op">=</span> df0[<span class="st">'label'</span>].value_counts().reset_index().rename(columns<span class="op">=</span>{<span class="st">'index'</span>: <span class="st">'label'</span>,<span class="st">'label'</span>:<span class="st">'count'</span>})</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>distribution[<span class="st">'proportion'</span>] <span class="op">=</span> distribution[<span class="st">'count'</span>]<span class="op">/</span><span class="bu">len</span>(df0)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'-----------------------------------'</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(distribution)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'-----------------------------------'</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> sns.barplot(x <span class="op">=</span> <span class="st">'label'</span>, y <span class="op">=</span> <span class="st">'count'</span>, data <span class="op">=</span> distribution)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Barplot of Health Insurance Company'</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>-----------------------------------
          label  count  proportion
0         Aetna     73    0.271375
1         Cigna     72    0.267658
2        Anthem     63    0.234201
3  UnitedHealth     61    0.226766
-----------------------------------</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="svm_text_files/figure-html/cell-4-output-2.png" width="585" height="449"></p>
</div>
</div>
</section>
<section id="random-classifier" class="level2">
<h2 class="anchored" data-anchor-id="random-classifier">Random Classifier</h2>
<div class="cell" data-execution_count="4">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> random_classifier(y_data):</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    random.seed(<span class="dv">909391</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    ypred<span class="op">=</span>[]</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>,<span class="bu">len</span>(y_data)):</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>        ypred.append(np.random.choice(distribution[<span class="st">'label'</span>], p <span class="op">=</span> distribution[<span class="st">'proportion'</span>]))</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ypred</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="5">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> df0[<span class="st">'label'</span>]</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>predicted_label <span class="op">=</span> random_classifier(Y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="6">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> confusion_plot(y_data,y_pred):</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'----------------------Classification Report---------------------------'</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'ACCURACY:'</span>, accuracy_score(y_data, y_pred))</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'RECALL (Y = Aetna):'</span>, recall_score(y_data, y_pred,labels<span class="op">=</span>[distribution[<span class="st">'label'</span>][<span class="dv">0</span>]], average<span class="op">=</span><span class="st">'weighted'</span>))</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'RECALL (Y = Cigna):'</span>, recall_score(y_data, y_pred,labels<span class="op">=</span>[distribution[<span class="st">'label'</span>][<span class="dv">1</span>]], average<span class="op">=</span><span class="st">'weighted'</span>))</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'RECALL (Y = Anthem ):'</span>, recall_score(y_data, y_pred,labels<span class="op">=</span>[distribution[<span class="st">'label'</span>][<span class="dv">2</span>]], average<span class="op">=</span><span class="st">'weighted'</span>))</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'RECALL (Y = UnitedHealth):'</span>, recall_score(y_data, y_pred,labels<span class="op">=</span>[distribution[<span class="st">'label'</span>][<span class="dv">3</span>]], average<span class="op">=</span><span class="st">'weighted'</span>))</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'PRECISION (Y = Aetna):'</span>, precision_score(y_data,y_pred,labels<span class="op">=</span>[distribution[<span class="st">'label'</span>][<span class="dv">0</span>]],average<span class="op">=</span><span class="st">'weighted'</span>))</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'PRECISION (Y = Cigna):'</span>, precision_score(y_data,y_pred,labels<span class="op">=</span>[distribution[<span class="st">'label'</span>][<span class="dv">1</span>]], average<span class="op">=</span><span class="st">'weighted'</span>))</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'PRECISION (Y = Anthem):'</span>, precision_score(y_data,y_pred,labels<span class="op">=</span>[distribution[<span class="st">'label'</span>][<span class="dv">2</span>]], average<span class="op">=</span><span class="st">'weighted'</span>))</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'PRECISION (Y = UnitedHealth):'</span>, precision_score(y_data,y_pred,labels<span class="op">=</span>[distribution[<span class="st">'label'</span>][<span class="dv">3</span>]], average<span class="op">=</span><span class="st">'weighted'</span>))</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'--------------------------Confusion Matrix-----------------------------'</span>)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(confusion_matrix(y_data,y_pred))</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>    ConfusionMatrixDisplay.from_predictions(y_data, y_pred)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="7">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>confusion_plot(Y,predicted_label)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>----------------------Classification Report---------------------------
ACCURACY: 0.26765799256505574
RECALL (Y = Aetna): 0.273972602739726
RECALL (Y = Cigna): 0.2777777777777778
RECALL (Y = Anthem ): 0.2222222222222222
RECALL (Y = UnitedHealth): 0.29508196721311475
PRECISION (Y = Aetna): 0.3125
PRECISION (Y = Cigna): 0.2702702702702703
PRECISION (Y = Anthem): 0.21212121212121213
PRECISION (Y = UnitedHealth): 0.27692307692307694
--------------------------Confusion Matrix-----------------------------
[[20 18 19 16]
 [12 14 20 17]
 [17 21 20 14]
 [15 13 15 18]]</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="svm_text_files/figure-html/cell-8-output-2.png" width="575" height="434"></p>
</div>
</div>
</section>
<section id="feature-selection-support-vector-classifier" class="level2">
<h2 class="anchored" data-anchor-id="feature-selection-support-vector-classifier">Feature Selection: Support Vector Classifier</h2>
<p>For feature selection, I manually subsetted the original dataset and keep only the first 170 high frequency vocabulary in the columns. The method of how I select the features is similar to using the varianve threshold. If a word shows up only once or twice, it is not informative to train our data.Thus,keep only the high frequency words is the same as to keep the high variance ones.</p>
<div class="cell" data-execution_count="8">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df0[wf[<span class="st">'word'</span>][:<span class="dv">170</span>]]</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>ux <span class="op">=</span> np.mean(X,axis <span class="op">=</span> <span class="dv">0</span>) <span class="co"># NORMALIZE X</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>sx <span class="op">=</span> np.std(X,axis <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">170</span>):</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    X.iloc[:,i] <span class="op">=</span> (X.iloc[:,i] <span class="op">-</span> ux[i])<span class="op">/</span>sx[i]</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>x_train, x_test, y_train, y_test <span class="op">=</span> train_test_split(X, Y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">909391</span>)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"TRAINING SHAPES:"</span>,x_train.shape,y_train.shape)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"TEST SHAPES:"</span>,x_test.shape,y_test.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>TRAINING SHAPES: (215, 170) (215,)
TEST SHAPES: (54, 170) (54,)</code></pre>
</div>
</div>
</section>
<section id="hyperparameter-tuning" class="level2">
<h2 class="anchored" data-anchor-id="hyperparameter-tuning">Hyperparameter Tuning</h2>
<ul>
<li>Kernel Tuning</li>
</ul>
<p>The main hyperparameter of the SVM is the kernel. It maps the observations into some feature space. Ideally the observations are more easily (linearly) separable after this transformation. There are multiple standard kernels for this transformations, e.g.&nbsp;the linear kernel, the polynomial kernel and the radial kernel. The choice of the kernel and their hyperparameters affect greatly the separability of the classes (in classification) and the performance of the algorithm.</p>
<p>In Kernel tuning, we found that the best kernal to train our data is sigmoid whose accuracy for trainig is 98% and for testing is 93%.</p>
<div class="cell" data-execution_count="9">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>kernel <span class="op">=</span> [<span class="st">'linear'</span>, <span class="st">'poly'</span>, <span class="st">'rbf'</span>, <span class="st">'sigmoid'</span>]</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> kernel:</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> SVC(kernel <span class="op">=</span> i, degree <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    model.fit(x_train,y_train)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    yp_train <span class="op">=</span> model.predict(x_train)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    yp_test <span class="op">=</span> model.predict(x_test)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'---------------------------------------------------'</span>)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'For kernel: '</span>,i)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Training accuracy is: '</span>, accuracy_score(y_train, yp_train))</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Testing accuracy is: '</span>, accuracy_score(y_test, yp_test))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>---------------------------------------------------
For kernel:  linear
Training accuracy is:  1.0
Testing accuracy is:  0.9074074074074074
---------------------------------------------------
For kernel:  poly
Training accuracy is:  0.786046511627907
Testing accuracy is:  0.46296296296296297
---------------------------------------------------
For kernel:  rbf
Training accuracy is:  0.9953488372093023
Testing accuracy is:  0.8148148148148148
---------------------------------------------------
For kernel:  sigmoid
Training accuracy is:  0.986046511627907
Testing accuracy is:  0.9259259259259259</code></pre>
</div>
</div>
<ul>
<li>Gamma Tuning</li>
</ul>
<p>The gamma parameter defines how far the influence of a single training example reaches, with low values meaning 'far' and high values meaning 'close'. In other words, with low gamma, points far away from plausible seperation line are considered in calculation for the seperation line. Where as high gamma means the points close to plausible line are considered in calculation. After tuning, we found that the optimized gamma for our model is 0.01.</p>
<div class="cell" data-execution_count="10">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tunningResult(y_train, y_test, yp_train, yp_test):</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    accuracy_train <span class="op">=</span> accuracy_score(y_train, yp_train)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    recall_0_train <span class="op">=</span> recall_score(y_train, yp_train,labels<span class="op">=</span>[distribution[<span class="st">'label'</span>][<span class="dv">0</span>]], average<span class="op">=</span><span class="st">'weighted'</span>)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    recall_1_train <span class="op">=</span> recall_score(y_train, yp_train,labels<span class="op">=</span>[distribution[<span class="st">'label'</span>][<span class="dv">1</span>]], average<span class="op">=</span><span class="st">'weighted'</span>)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    recall_2_train <span class="op">=</span> recall_score(y_train, yp_train,labels<span class="op">=</span>[distribution[<span class="st">'label'</span>][<span class="dv">2</span>]], average<span class="op">=</span><span class="st">'weighted'</span>)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    recall_3_train <span class="op">=</span> recall_score(y_train, yp_train,labels<span class="op">=</span>[distribution[<span class="st">'label'</span>][<span class="dv">3</span>]], average<span class="op">=</span><span class="st">'weighted'</span>)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    accuracy_test <span class="op">=</span> accuracy_score(y_test, yp_test)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>    recall_0_test <span class="op">=</span> recall_score(y_test, yp_test,labels<span class="op">=</span>distribution[<span class="st">'label'</span>][<span class="dv">0</span>], average<span class="op">=</span><span class="st">'weighted'</span>)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>    recall_1_test <span class="op">=</span> recall_score(y_test, yp_test,labels<span class="op">=</span>[distribution[<span class="st">'label'</span>][<span class="dv">1</span>]], average<span class="op">=</span><span class="st">'weighted'</span>)</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>    recall_2_test <span class="op">=</span> recall_score(y_test, yp_test,labels<span class="op">=</span>[distribution[<span class="st">'label'</span>][<span class="dv">2</span>]], average<span class="op">=</span><span class="st">'weighted'</span>)</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>    recall_3_test <span class="op">=</span> recall_score(y_test, yp_test,labels<span class="op">=</span>[distribution[<span class="st">'label'</span>][<span class="dv">3</span>]], average<span class="op">=</span><span class="st">'weighted'</span>)</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [accuracy_train, recall_0_train,recall_1_train,recall_2_train,recall_3_train],[accuracy_test,recall_0_test,recall_1_test,recall_2_test,recall_3_test]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="11">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>test_results<span class="op">=</span>[]</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>train_results<span class="op">=</span>[]</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>gamma <span class="op">=</span> [<span class="fl">0.0001</span>, <span class="fl">0.001</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="fl">1.0</span>]</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> gamma:</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> SVC(kernel <span class="op">=</span> <span class="st">'sigmoid'</span>, gamma<span class="op">=</span>i)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    model.fit(x_train,y_train)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    yp_train <span class="op">=</span> model.predict(x_train)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>    yp_test <span class="op">=</span> model.predict(x_test)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>    a,b <span class="op">=</span> tunningResult(y_train, y_test, yp_train, yp_test)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>    test_results.append([i]<span class="op">+</span>b)</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>    train_results.append([i]<span class="op">+</span>a)</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>test_results <span class="op">=</span> pd.DataFrame(test_results)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>train_results <span class="op">=</span> pd.DataFrame(train_results)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="12">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(test_results)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>        0         1         2         3         4         5
0  0.0001  0.240741  0.240741  1.000000  0.000000  0.000000
1  0.0010  0.611111  0.611111  1.000000  0.133333  0.636364
2  0.0100  0.888889  0.888889  0.846154  1.000000  0.909091
3  0.1000  0.796296  0.796296  0.615385  0.933333  0.727273
4  1.0000  0.759259  0.759259  0.461538  0.866667  0.818182</code></pre>
</div>
</div>
<div class="cell" data-execution_count="13">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> resultPlot(train_results,test_results,param):</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>    sns.set_theme(style<span class="op">=</span><span class="st">'whitegrid'</span>, palette<span class="op">=</span><span class="st">"Pastel1"</span>)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    fig,ax <span class="op">=</span> plt.subplots(<span class="dv">2</span>,<span class="dv">3</span>)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    fig.set_size_inches(<span class="dv">20</span>,<span class="dv">10</span>)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    axis1 <span class="op">=</span> np.arange(<span class="bu">len</span>(test_results))</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>    axis2 <span class="op">=</span> [x <span class="op">+</span> <span class="fl">.25</span> <span class="cf">for</span> x <span class="kw">in</span> axis1]</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>    ax1 <span class="op">=</span> ax[<span class="dv">0</span>,<span class="dv">0</span>]</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>    ax1.bar(axis1,train_results[<span class="dv">1</span>],label <span class="op">=</span> <span class="st">'Train'</span>, width<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>    ax1.bar(axis2,test_results[<span class="dv">1</span>],label <span class="op">=</span> <span class="st">'Test'</span>,width<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>    ax1.set_xlabel(param)</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>    ax1.set_ylabel(<span class="st">"ACCURACY: Training and Test"</span>)</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>    ax1.legend()</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>    ax1.set_xticks([x <span class="op">+</span> <span class="fl">.5</span> <span class="cf">for</span> x <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(test_results))], test_results[<span class="dv">0</span>])</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>    ax2 <span class="op">=</span> ax[<span class="dv">0</span>,<span class="dv">1</span>]</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>    ax2.bar(axis1,train_results[<span class="dv">2</span>],label <span class="op">=</span> <span class="st">'Train'</span>, width<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>    ax2.bar(axis2,test_results[<span class="dv">2</span>],label <span class="op">=</span> <span class="st">'Test'</span>, width<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>    ax2.set_xlabel(param)</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>    ax2.legend()</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>    ax2.set_xticks([x <span class="op">+</span> <span class="fl">.5</span> <span class="cf">for</span> x <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(test_results))], test_results[<span class="dv">0</span>])</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>    ax2.set_ylabel(<span class="st">"RECALL(Y=Aetna): Training and Test"</span>)</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>    ax3 <span class="op">=</span> ax[<span class="dv">0</span>,<span class="dv">2</span>]</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>    ax3.bar(axis1,train_results[<span class="dv">3</span>],label <span class="op">=</span> <span class="st">'Train'</span>, width<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>    ax3.bar(axis2,test_results[<span class="dv">3</span>],label <span class="op">=</span> <span class="st">'Test'</span>, width<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>    ax3.set_xlabel(param)</span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a>    ax3.legend()</span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a>    ax3.set_ylabel(<span class="st">"RECALL(Y=Cigna): Training and Test"</span>)</span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>    ax3.set_xticks([x <span class="op">+</span> <span class="fl">.5</span> <span class="cf">for</span> x <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(test_results))], test_results[<span class="dv">0</span>])</span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a>    ax4 <span class="op">=</span> ax[<span class="dv">1</span>,<span class="dv">0</span>]</span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>    ax4.bar(axis1,train_results[<span class="dv">4</span>],label <span class="op">=</span> <span class="st">'Train'</span>, width<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a>    ax4.bar(axis2,test_results[<span class="dv">4</span>],label <span class="op">=</span> <span class="st">'Test'</span>, width<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a>    ax4.set_xlabel(param)</span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a>    ax4.legend()</span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a>    ax4.set_ylabel(<span class="st">"RECALL(Y=Anthem): Training and Test"</span>)</span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a>    ax4.set_xticks([x <span class="op">+</span> <span class="fl">.5</span> <span class="cf">for</span> x <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(test_results))], test_results[<span class="dv">0</span>])</span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a>    ax5 <span class="op">=</span> ax[<span class="dv">1</span>,<span class="dv">1</span>]</span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a>    ax5.bar(axis1,train_results[<span class="dv">5</span>],label <span class="op">=</span> <span class="st">'Train'</span>, width<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a>    ax5.bar(axis2,test_results[<span class="dv">5</span>],label <span class="op">=</span> <span class="st">'Test'</span>, width<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a>    ax5.set_xlabel(param)</span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a>    ax5.legend()</span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a>    ax5.set_ylabel(<span class="st">"RECALL(Y=UnitedHealth): Training and Test"</span>)</span>
<span id="cb18-45"><a href="#cb18-45" aria-hidden="true" tabindex="-1"></a>    ax5.set_xticks([x <span class="op">+</span> <span class="fl">.5</span> <span class="cf">for</span> x <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(test_results))], test_results[<span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="14">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>resultPlot(train_results, test_results, <span class="st">'Gamma'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="svm_text_files/figure-html/cell-15-output-1.png" width="1570" height="806"></p>
</div>
</div>
<ul>
<li>Regularization (C parameter) Tuning</li>
</ul>
<p>The regularization (C) parameter tells the SVM optimization how much you want to avoid misclassifying. For large value C, the optimization will chose a smaller-margin hyperplane if that hyperplane does a better job getting all the training points classified correclty. Conversely, a very small C parameter will cause the optimizer to look for a large-margin seperating hyperplane, even if that hyperplane misclassifies more points. The optimized C parameter after tuning is 1.</p>
<div class="cell" data-execution_count="15">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>test_results<span class="op">=</span>[]</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>train_results<span class="op">=</span>[]</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>C <span class="op">=</span> [<span class="fl">0.1</span>,<span class="fl">1.0</span>,<span class="fl">5.0</span>,<span class="fl">10.0</span>,<span class="fl">50.0</span>,<span class="fl">100.0</span>,<span class="fl">1000.0</span> ]</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> C:</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> SVC(kernel <span class="op">=</span> <span class="st">'sigmoid'</span>, gamma<span class="op">=</span><span class="fl">0.01</span>, C <span class="op">=</span> i)</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>    model.fit(x_train,y_train)</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>    yp_train <span class="op">=</span> model.predict(x_train)</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>    yp_test <span class="op">=</span> model.predict(x_test)</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>    a,b <span class="op">=</span> tunningResult(y_train, y_test, yp_train, yp_test)</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>    test_results.append([i]<span class="op">+</span>b)</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>    train_results.append([i]<span class="op">+</span>a)</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>test_results <span class="op">=</span> pd.DataFrame(test_results)</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>train_results <span class="op">=</span> pd.DataFrame(train_results)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="16">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(test_results)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>        0         1         2         3         4         5
0     0.1  0.537037  0.537037  1.000000  0.000000  0.545455
1     1.0  0.888889  0.888889  0.846154  1.000000  0.909091
2     5.0  0.796296  0.796296  0.615385  1.000000  0.727273
3    10.0  0.740741  0.740741  0.538462  1.000000  0.727273
4    50.0  0.759259  0.759259  0.538462  0.933333  0.818182
5   100.0  0.777778  0.777778  0.615385  1.000000  0.727273
6  1000.0  0.777778  0.777778  0.615385  1.000000  0.727273</code></pre>
</div>
</div>
<div class="cell" data-execution_count="17">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>resultPlot(train_results, test_results, <span class="st">'Gamma'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="svm_text_files/figure-html/cell-18-output-1.png" width="1570" height="805"></p>
</div>
</div>
</section>
<section id="final-result-and-conclusion" class="level2">
<h2 class="anchored" data-anchor-id="final-result-and-conclusion">Final Result and Conclusion</h2>
<p>In the final model, I used the set of optimized the hyperparameter in SVC to train on the training sets. The result is surprisingly good. According to the printed classification report, the training accuracy is 94.4% and the testing accuracy is around 89%. This means that when we input some new data into this model, the likelihood of outputting the correct label is 89%, which is considered very accurate for a four-label data. We can also double-check the confusion matrix an see that almost all the points are located in the diagnol.</p>
<div class="cell" data-execution_count="18">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>final_model <span class="op">=</span> SVC(kernel <span class="op">=</span> <span class="st">'sigmoid'</span>, gamma<span class="op">=</span><span class="fl">0.01</span>, C <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>final_model.fit(x_train,y_train)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>yp_train <span class="op">=</span> final_model.predict(x_train)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>yp_test <span class="op">=</span> final_model.predict(x_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="19">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'----------------------------Training---------------------------------'</span>)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>confusion_plot(y_train, yp_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>----------------------------Training---------------------------------
----------------------Classification Report---------------------------
ACCURACY: 0.9441860465116279
RECALL (Y = Aetna): 0.9655172413793104
RECALL (Y = Cigna): 0.9152542372881356
RECALL (Y = Anthem ): 0.9791666666666666
RECALL (Y = UnitedHealth): 0.92
PRECISION (Y = Aetna): 0.9491525423728814
PRECISION (Y = Cigna): 0.9152542372881356
PRECISION (Y = Anthem): 1.0
PRECISION (Y = UnitedHealth): 0.92
--------------------------Confusion Matrix-----------------------------
[[56  0  2  0]
 [ 0 47  1  0]
 [ 1  0 54  4]
 [ 2  0  2 46]]</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="svm_text_files/figure-html/cell-20-output-2.png" width="580" height="435"></p>
</div>
</div>
<div class="cell" data-execution_count="20">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'----------------------------Testing---------------------------------'</span>)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>confusion_plot(y_test, yp_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>----------------------------Testing---------------------------------
----------------------Classification Report---------------------------
ACCURACY: 0.8888888888888888
RECALL (Y = Aetna): 0.8
RECALL (Y = Cigna): 0.8461538461538461
RECALL (Y = Anthem ): 1.0
RECALL (Y = UnitedHealth): 0.9090909090909091
PRECISION (Y = Aetna): 0.9230769230769231
PRECISION (Y = Cigna): 0.7857142857142857
PRECISION (Y = Anthem): 0.8823529411764706
PRECISION (Y = UnitedHealth): 1.0
--------------------------Confusion Matrix-----------------------------
[[12  0  3  0]
 [ 0 15  0  0]
 [ 1  1 11  0]
 [ 0  1  0 10]]</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="svm_text_files/figure-html/cell-21-output-2.png" width="580" height="435"></p>
</div>
</div>
<!-- -->

</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb29" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="an">jupyter:</span><span class="co"> python3</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "SVM on Text Data"</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "10/24/2022"</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="an">pdf-engine:</span><span class="co"> lualatex</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a><span class="co">    theme : Minty</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a><span class="co">    toc: true</span></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a><span class="co">    code-tools: true</span></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a><span class="co">    code-fold: true</span></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a><span class="co">    code-summary: "Code"</span></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a><span class="co">    toc-title: Contents</span></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a><span class="an">execute:</span></span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a><span class="co">    warning: false</span></span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a><span class="fu">### Method</span></span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a>**What is Support Vector Machines?**</span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a>A support vector machine (SVM) is a supervised machine learning model that uses classification algorithms for two-group classification problems. After giving an SVM model sets of labeled training data for each category, they're able to categorize new text.</span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a>Compared to newer algorithms like neural networks, they have two main advantages: higher speed and better performance with a limited number of samples (in the thousands). This makes the algorithm very suitable for text classification problems, where it's common to have access to a dataset of at most a couple of thousands of tagged samples.</span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-26"><a href="#cb29-26" aria-hidden="true" tabindex="-1"></a>**How Does SVM Work?**  </span>
<span id="cb29-27"><a href="#cb29-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-28"><a href="#cb29-28" aria-hidden="true" tabindex="-1"></a>The basics of Support Vector Machines and how it works are best understood with a simple example. Let's imagine we have two tags: red and blue, and our data has two features: x and y. We want a classifier that, given a pair of (x,y) coordinates, outputs if it's either red or blue. We plot our already labeled training data on a plane:  </span>
<span id="cb29-29"><a href="#cb29-29" aria-hidden="true" tabindex="-1"></a><span class="al">![Our labeled data](labeled.png)</span></span>
<span id="cb29-30"><a href="#cb29-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-31"><a href="#cb29-31" aria-hidden="true" tabindex="-1"></a>A support vector machine takes these data points and outputs the hyperplane (which in two dimensions it's simply a line) that best separates the tags. This line is the decision boundary: anything that falls to one side of it we will classify as blue, and anything that falls to the other as red.  </span>
<span id="cb29-32"><a href="#cb29-32" aria-hidden="true" tabindex="-1"></a><span class="al">![In 2D, the best hyperplane is simply a line](2D.png)</span></span>
<span id="cb29-33"><a href="#cb29-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-34"><a href="#cb29-34" aria-hidden="true" tabindex="-1"></a>But, what exactly is the best hyperplane? For SVM, it's the one that maximizes the margins from both tags. In other words: the hyperplane (remember it's a line in this case) whose distance to the nearest element of each tag is the largest.</span>
<span id="cb29-35"><a href="#cb29-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-38"><a href="#cb29-38" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-39"><a href="#cb29-39" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb29-40"><a href="#cb29-40" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb29-41"><a href="#cb29-41" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb29-42"><a href="#cb29-42" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb29-43"><a href="#cb29-43" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, ConfusionMatrixDisplay</span>
<span id="cb29-44"><a href="#cb29-44" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> tree</span>
<span id="cb29-45"><a href="#cb29-45" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb29-46"><a href="#cb29-46" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> precision_score</span>
<span id="cb29-47"><a href="#cb29-47" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> recall_score</span>
<span id="cb29-48"><a href="#cb29-48" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb29-49"><a href="#cb29-49" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb29-50"><a href="#cb29-50" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb29-51"><a href="#cb29-51" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report, confusion_matrix</span>
<span id="cb29-52"><a href="#cb29-52" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-53"><a href="#cb29-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-54"><a href="#cb29-54" aria-hidden="true" tabindex="-1"></a><span class="fu">## Class Distribution</span></span>
<span id="cb29-55"><a href="#cb29-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-56"><a href="#cb29-56" aria-hidden="true" tabindex="-1"></a>For text data, the label consists of four insurance company. I gathered the data from twitter API using the hashtags of these insurance company. Each tweet in the data belongs to a topic of hashtag. Based on the output, we can see that the distribution of labels is very balanced. Having a balanced data set for a model would generate higher accuracy models, higher balanced accuracy and balanced detection rate. Hence, its important to have a balanced data set for a classification model. </span>
<span id="cb29-59"><a href="#cb29-59" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-60"><a href="#cb29-60" aria-hidden="true" tabindex="-1"></a>df0 <span class="op">=</span> pd.read_csv(<span class="st">'/Users/liumingqian/anly-501-project-liumingqian0511/data/01-modified-data/vec.csv'</span>)</span>
<span id="cb29-61"><a href="#cb29-61" aria-hidden="true" tabindex="-1"></a>wf <span class="op">=</span> pd.read_csv(<span class="st">'/Users/liumingqian/anly-501-project-liumingqian0511/data/01-modified-data/word_frequency_text.csv'</span>)</span>
<span id="cb29-62"><a href="#cb29-62" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-63"><a href="#cb29-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-66"><a href="#cb29-66" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-67"><a href="#cb29-67" aria-hidden="true" tabindex="-1"></a>distribution <span class="op">=</span> df0[<span class="st">'label'</span>].value_counts().reset_index().rename(columns<span class="op">=</span>{<span class="st">'index'</span>: <span class="st">'label'</span>,<span class="st">'label'</span>:<span class="st">'count'</span>})</span>
<span id="cb29-68"><a href="#cb29-68" aria-hidden="true" tabindex="-1"></a>distribution[<span class="st">'proportion'</span>] <span class="op">=</span> distribution[<span class="st">'count'</span>]<span class="op">/</span><span class="bu">len</span>(df0)</span>
<span id="cb29-69"><a href="#cb29-69" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'-----------------------------------'</span>)</span>
<span id="cb29-70"><a href="#cb29-70" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(distribution)</span>
<span id="cb29-71"><a href="#cb29-71" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'-----------------------------------'</span>)</span>
<span id="cb29-72"><a href="#cb29-72" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> sns.barplot(x <span class="op">=</span> <span class="st">'label'</span>, y <span class="op">=</span> <span class="st">'count'</span>, data <span class="op">=</span> distribution)</span>
<span id="cb29-73"><a href="#cb29-73" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Barplot of Health Insurance Company'</span>)</span>
<span id="cb29-74"><a href="#cb29-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-75"><a href="#cb29-75" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb29-76"><a href="#cb29-76" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-77"><a href="#cb29-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-78"><a href="#cb29-78" aria-hidden="true" tabindex="-1"></a><span class="fu">## Random Classifier</span></span>
<span id="cb29-79"><a href="#cb29-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-82"><a href="#cb29-82" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-83"><a href="#cb29-83" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> random_classifier(y_data):</span>
<span id="cb29-84"><a href="#cb29-84" aria-hidden="true" tabindex="-1"></a>    random.seed(<span class="dv">909391</span>)</span>
<span id="cb29-85"><a href="#cb29-85" aria-hidden="true" tabindex="-1"></a>    ypred<span class="op">=</span>[]</span>
<span id="cb29-86"><a href="#cb29-86" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>,<span class="bu">len</span>(y_data)):</span>
<span id="cb29-87"><a href="#cb29-87" aria-hidden="true" tabindex="-1"></a>        ypred.append(np.random.choice(distribution[<span class="st">'label'</span>], p <span class="op">=</span> distribution[<span class="st">'proportion'</span>]))</span>
<span id="cb29-88"><a href="#cb29-88" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> ypred</span>
<span id="cb29-89"><a href="#cb29-89" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-90"><a href="#cb29-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-93"><a href="#cb29-93" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-94"><a href="#cb29-94" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> df0[<span class="st">'label'</span>]</span>
<span id="cb29-95"><a href="#cb29-95" aria-hidden="true" tabindex="-1"></a>predicted_label <span class="op">=</span> random_classifier(Y)</span>
<span id="cb29-96"><a href="#cb29-96" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-97"><a href="#cb29-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-100"><a href="#cb29-100" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-101"><a href="#cb29-101" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> confusion_plot(y_data,y_pred):</span>
<span id="cb29-102"><a href="#cb29-102" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'----------------------Classification Report---------------------------'</span>)</span>
<span id="cb29-103"><a href="#cb29-103" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'ACCURACY:'</span>, accuracy_score(y_data, y_pred))</span>
<span id="cb29-104"><a href="#cb29-104" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'RECALL (Y = Aetna):'</span>, recall_score(y_data, y_pred,labels<span class="op">=</span>[distribution[<span class="st">'label'</span>][<span class="dv">0</span>]], average<span class="op">=</span><span class="st">'weighted'</span>))</span>
<span id="cb29-105"><a href="#cb29-105" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'RECALL (Y = Cigna):'</span>, recall_score(y_data, y_pred,labels<span class="op">=</span>[distribution[<span class="st">'label'</span>][<span class="dv">1</span>]], average<span class="op">=</span><span class="st">'weighted'</span>))</span>
<span id="cb29-106"><a href="#cb29-106" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'RECALL (Y = Anthem ):'</span>, recall_score(y_data, y_pred,labels<span class="op">=</span>[distribution[<span class="st">'label'</span>][<span class="dv">2</span>]], average<span class="op">=</span><span class="st">'weighted'</span>))</span>
<span id="cb29-107"><a href="#cb29-107" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'RECALL (Y = UnitedHealth):'</span>, recall_score(y_data, y_pred,labels<span class="op">=</span>[distribution[<span class="st">'label'</span>][<span class="dv">3</span>]], average<span class="op">=</span><span class="st">'weighted'</span>))</span>
<span id="cb29-108"><a href="#cb29-108" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'PRECISION (Y = Aetna):'</span>, precision_score(y_data,y_pred,labels<span class="op">=</span>[distribution[<span class="st">'label'</span>][<span class="dv">0</span>]],average<span class="op">=</span><span class="st">'weighted'</span>))</span>
<span id="cb29-109"><a href="#cb29-109" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'PRECISION (Y = Cigna):'</span>, precision_score(y_data,y_pred,labels<span class="op">=</span>[distribution[<span class="st">'label'</span>][<span class="dv">1</span>]], average<span class="op">=</span><span class="st">'weighted'</span>))</span>
<span id="cb29-110"><a href="#cb29-110" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'PRECISION (Y = Anthem):'</span>, precision_score(y_data,y_pred,labels<span class="op">=</span>[distribution[<span class="st">'label'</span>][<span class="dv">2</span>]], average<span class="op">=</span><span class="st">'weighted'</span>))</span>
<span id="cb29-111"><a href="#cb29-111" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'PRECISION (Y = UnitedHealth):'</span>, precision_score(y_data,y_pred,labels<span class="op">=</span>[distribution[<span class="st">'label'</span>][<span class="dv">3</span>]], average<span class="op">=</span><span class="st">'weighted'</span>))</span>
<span id="cb29-112"><a href="#cb29-112" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'--------------------------Confusion Matrix-----------------------------'</span>)</span>
<span id="cb29-113"><a href="#cb29-113" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(confusion_matrix(y_data,y_pred))</span>
<span id="cb29-114"><a href="#cb29-114" aria-hidden="true" tabindex="-1"></a>    ConfusionMatrixDisplay.from_predictions(y_data, y_pred)</span>
<span id="cb29-115"><a href="#cb29-115" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb29-116"><a href="#cb29-116" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-117"><a href="#cb29-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-120"><a href="#cb29-120" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-121"><a href="#cb29-121" aria-hidden="true" tabindex="-1"></a>confusion_plot(Y,predicted_label)</span>
<span id="cb29-122"><a href="#cb29-122" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-123"><a href="#cb29-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-124"><a href="#cb29-124" aria-hidden="true" tabindex="-1"></a><span class="fu">## Feature Selection: Support Vector Classifier</span></span>
<span id="cb29-125"><a href="#cb29-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-126"><a href="#cb29-126" aria-hidden="true" tabindex="-1"></a>For feature selection, I manually subsetted the original dataset and keep only the first 170 high frequency vocabulary in the columns. The method of how I select the features is similar to using the varianve threshold. If a word shows up only once or twice, it is not informative to train our data.Thus,keep only the high frequency words is the same as to keep the high variance ones.</span>
<span id="cb29-129"><a href="#cb29-129" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-130"><a href="#cb29-130" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df0[wf[<span class="st">'word'</span>][:<span class="dv">170</span>]]</span>
<span id="cb29-131"><a href="#cb29-131" aria-hidden="true" tabindex="-1"></a>ux <span class="op">=</span> np.mean(X,axis <span class="op">=</span> <span class="dv">0</span>) <span class="co"># NORMALIZE X</span></span>
<span id="cb29-132"><a href="#cb29-132" aria-hidden="true" tabindex="-1"></a>sx <span class="op">=</span> np.std(X,axis <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb29-133"><a href="#cb29-133" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">170</span>):</span>
<span id="cb29-134"><a href="#cb29-134" aria-hidden="true" tabindex="-1"></a>    X.iloc[:,i] <span class="op">=</span> (X.iloc[:,i] <span class="op">-</span> ux[i])<span class="op">/</span>sx[i]</span>
<span id="cb29-135"><a href="#cb29-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-136"><a href="#cb29-136" aria-hidden="true" tabindex="-1"></a>x_train, x_test, y_train, y_test <span class="op">=</span> train_test_split(X, Y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">909391</span>)</span>
<span id="cb29-137"><a href="#cb29-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-138"><a href="#cb29-138" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"TRAINING SHAPES:"</span>,x_train.shape,y_train.shape)</span>
<span id="cb29-139"><a href="#cb29-139" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"TEST SHAPES:"</span>,x_test.shape,y_test.shape)</span>
<span id="cb29-140"><a href="#cb29-140" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-141"><a href="#cb29-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-142"><a href="#cb29-142" aria-hidden="true" tabindex="-1"></a><span class="fu">## Hyperparameter Tuning</span></span>
<span id="cb29-143"><a href="#cb29-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-144"><a href="#cb29-144" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Kernel Tuning</span>
<span id="cb29-145"><a href="#cb29-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-146"><a href="#cb29-146" aria-hidden="true" tabindex="-1"></a>The main hyperparameter of the SVM is the kernel. It maps the observations into some feature space. Ideally the observations are more easily (linearly) separable after this transformation. There are multiple standard kernels for this transformations, e.g. the linear kernel, the polynomial kernel and the radial kernel. The choice of the kernel and their hyperparameters affect greatly the separability of the classes (in classification) and the performance of the algorithm.</span>
<span id="cb29-147"><a href="#cb29-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-148"><a href="#cb29-148" aria-hidden="true" tabindex="-1"></a>In Kernel tuning, we found that the best kernal to train our data is sigmoid whose accuracy for trainig is 98% and for testing is 93%.</span>
<span id="cb29-151"><a href="#cb29-151" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-152"><a href="#cb29-152" aria-hidden="true" tabindex="-1"></a>kernel <span class="op">=</span> [<span class="st">'linear'</span>, <span class="st">'poly'</span>, <span class="st">'rbf'</span>, <span class="st">'sigmoid'</span>]</span>
<span id="cb29-153"><a href="#cb29-153" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> kernel:</span>
<span id="cb29-154"><a href="#cb29-154" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> SVC(kernel <span class="op">=</span> i, degree <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb29-155"><a href="#cb29-155" aria-hidden="true" tabindex="-1"></a>    model.fit(x_train,y_train)</span>
<span id="cb29-156"><a href="#cb29-156" aria-hidden="true" tabindex="-1"></a>    yp_train <span class="op">=</span> model.predict(x_train)</span>
<span id="cb29-157"><a href="#cb29-157" aria-hidden="true" tabindex="-1"></a>    yp_test <span class="op">=</span> model.predict(x_test)</span>
<span id="cb29-158"><a href="#cb29-158" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'---------------------------------------------------'</span>)</span>
<span id="cb29-159"><a href="#cb29-159" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'For kernel: '</span>,i)</span>
<span id="cb29-160"><a href="#cb29-160" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Training accuracy is: '</span>, accuracy_score(y_train, yp_train))</span>
<span id="cb29-161"><a href="#cb29-161" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'Testing accuracy is: '</span>, accuracy_score(y_test, yp_test))</span>
<span id="cb29-162"><a href="#cb29-162" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-163"><a href="#cb29-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-164"><a href="#cb29-164" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Gamma Tuning</span>
<span id="cb29-165"><a href="#cb29-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-166"><a href="#cb29-166" aria-hidden="true" tabindex="-1"></a>The gamma parameter defines how far the influence of a single training example reaches, with low values meaning 'far' and high values meaning 'close'. In other words, with low gamma, points far away from plausible seperation line are considered in calculation for the seperation line. Where as high gamma means the points close to plausible line are considered in calculation. After tuning, we found that the optimized gamma for our model is 0.01.</span>
<span id="cb29-169"><a href="#cb29-169" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-170"><a href="#cb29-170" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tunningResult(y_train, y_test, yp_train, yp_test):</span>
<span id="cb29-171"><a href="#cb29-171" aria-hidden="true" tabindex="-1"></a>    accuracy_train <span class="op">=</span> accuracy_score(y_train, yp_train)</span>
<span id="cb29-172"><a href="#cb29-172" aria-hidden="true" tabindex="-1"></a>    recall_0_train <span class="op">=</span> recall_score(y_train, yp_train,labels<span class="op">=</span>[distribution[<span class="st">'label'</span>][<span class="dv">0</span>]], average<span class="op">=</span><span class="st">'weighted'</span>)</span>
<span id="cb29-173"><a href="#cb29-173" aria-hidden="true" tabindex="-1"></a>    recall_1_train <span class="op">=</span> recall_score(y_train, yp_train,labels<span class="op">=</span>[distribution[<span class="st">'label'</span>][<span class="dv">1</span>]], average<span class="op">=</span><span class="st">'weighted'</span>)</span>
<span id="cb29-174"><a href="#cb29-174" aria-hidden="true" tabindex="-1"></a>    recall_2_train <span class="op">=</span> recall_score(y_train, yp_train,labels<span class="op">=</span>[distribution[<span class="st">'label'</span>][<span class="dv">2</span>]], average<span class="op">=</span><span class="st">'weighted'</span>)</span>
<span id="cb29-175"><a href="#cb29-175" aria-hidden="true" tabindex="-1"></a>    recall_3_train <span class="op">=</span> recall_score(y_train, yp_train,labels<span class="op">=</span>[distribution[<span class="st">'label'</span>][<span class="dv">3</span>]], average<span class="op">=</span><span class="st">'weighted'</span>)</span>
<span id="cb29-176"><a href="#cb29-176" aria-hidden="true" tabindex="-1"></a>    accuracy_test <span class="op">=</span> accuracy_score(y_test, yp_test)</span>
<span id="cb29-177"><a href="#cb29-177" aria-hidden="true" tabindex="-1"></a>    recall_0_test <span class="op">=</span> recall_score(y_test, yp_test,labels<span class="op">=</span>distribution[<span class="st">'label'</span>][<span class="dv">0</span>], average<span class="op">=</span><span class="st">'weighted'</span>)</span>
<span id="cb29-178"><a href="#cb29-178" aria-hidden="true" tabindex="-1"></a>    recall_1_test <span class="op">=</span> recall_score(y_test, yp_test,labels<span class="op">=</span>[distribution[<span class="st">'label'</span>][<span class="dv">1</span>]], average<span class="op">=</span><span class="st">'weighted'</span>)</span>
<span id="cb29-179"><a href="#cb29-179" aria-hidden="true" tabindex="-1"></a>    recall_2_test <span class="op">=</span> recall_score(y_test, yp_test,labels<span class="op">=</span>[distribution[<span class="st">'label'</span>][<span class="dv">2</span>]], average<span class="op">=</span><span class="st">'weighted'</span>)</span>
<span id="cb29-180"><a href="#cb29-180" aria-hidden="true" tabindex="-1"></a>    recall_3_test <span class="op">=</span> recall_score(y_test, yp_test,labels<span class="op">=</span>[distribution[<span class="st">'label'</span>][<span class="dv">3</span>]], average<span class="op">=</span><span class="st">'weighted'</span>)</span>
<span id="cb29-181"><a href="#cb29-181" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [accuracy_train, recall_0_train,recall_1_train,recall_2_train,recall_3_train],[accuracy_test,recall_0_test,recall_1_test,recall_2_test,recall_3_test]</span>
<span id="cb29-182"><a href="#cb29-182" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-183"><a href="#cb29-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-186"><a href="#cb29-186" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-187"><a href="#cb29-187" aria-hidden="true" tabindex="-1"></a>test_results<span class="op">=</span>[]</span>
<span id="cb29-188"><a href="#cb29-188" aria-hidden="true" tabindex="-1"></a>train_results<span class="op">=</span>[]</span>
<span id="cb29-189"><a href="#cb29-189" aria-hidden="true" tabindex="-1"></a>gamma <span class="op">=</span> [<span class="fl">0.0001</span>, <span class="fl">0.001</span>, <span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="fl">1.0</span>]</span>
<span id="cb29-190"><a href="#cb29-190" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> gamma:</span>
<span id="cb29-191"><a href="#cb29-191" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> SVC(kernel <span class="op">=</span> <span class="st">'sigmoid'</span>, gamma<span class="op">=</span>i)</span>
<span id="cb29-192"><a href="#cb29-192" aria-hidden="true" tabindex="-1"></a>    model.fit(x_train,y_train)</span>
<span id="cb29-193"><a href="#cb29-193" aria-hidden="true" tabindex="-1"></a>    yp_train <span class="op">=</span> model.predict(x_train)</span>
<span id="cb29-194"><a href="#cb29-194" aria-hidden="true" tabindex="-1"></a>    yp_test <span class="op">=</span> model.predict(x_test)</span>
<span id="cb29-195"><a href="#cb29-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-196"><a href="#cb29-196" aria-hidden="true" tabindex="-1"></a>    a,b <span class="op">=</span> tunningResult(y_train, y_test, yp_train, yp_test)</span>
<span id="cb29-197"><a href="#cb29-197" aria-hidden="true" tabindex="-1"></a>    test_results.append([i]<span class="op">+</span>b)</span>
<span id="cb29-198"><a href="#cb29-198" aria-hidden="true" tabindex="-1"></a>    train_results.append([i]<span class="op">+</span>a)</span>
<span id="cb29-199"><a href="#cb29-199" aria-hidden="true" tabindex="-1"></a>test_results <span class="op">=</span> pd.DataFrame(test_results)</span>
<span id="cb29-200"><a href="#cb29-200" aria-hidden="true" tabindex="-1"></a>train_results <span class="op">=</span> pd.DataFrame(train_results)</span>
<span id="cb29-201"><a href="#cb29-201" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-202"><a href="#cb29-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-205"><a href="#cb29-205" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-206"><a href="#cb29-206" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(test_results)</span>
<span id="cb29-207"><a href="#cb29-207" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-208"><a href="#cb29-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-211"><a href="#cb29-211" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-212"><a href="#cb29-212" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> resultPlot(train_results,test_results,param):</span>
<span id="cb29-213"><a href="#cb29-213" aria-hidden="true" tabindex="-1"></a>    sns.set_theme(style<span class="op">=</span><span class="st">'whitegrid'</span>, palette<span class="op">=</span><span class="st">"Pastel1"</span>)</span>
<span id="cb29-214"><a href="#cb29-214" aria-hidden="true" tabindex="-1"></a>    fig,ax <span class="op">=</span> plt.subplots(<span class="dv">2</span>,<span class="dv">3</span>)</span>
<span id="cb29-215"><a href="#cb29-215" aria-hidden="true" tabindex="-1"></a>    fig.set_size_inches(<span class="dv">20</span>,<span class="dv">10</span>)</span>
<span id="cb29-216"><a href="#cb29-216" aria-hidden="true" tabindex="-1"></a>    axis1 <span class="op">=</span> np.arange(<span class="bu">len</span>(test_results))</span>
<span id="cb29-217"><a href="#cb29-217" aria-hidden="true" tabindex="-1"></a>    axis2 <span class="op">=</span> [x <span class="op">+</span> <span class="fl">.25</span> <span class="cf">for</span> x <span class="kw">in</span> axis1]</span>
<span id="cb29-218"><a href="#cb29-218" aria-hidden="true" tabindex="-1"></a>    ax1 <span class="op">=</span> ax[<span class="dv">0</span>,<span class="dv">0</span>]</span>
<span id="cb29-219"><a href="#cb29-219" aria-hidden="true" tabindex="-1"></a>    ax1.bar(axis1,train_results[<span class="dv">1</span>],label <span class="op">=</span> <span class="st">'Train'</span>, width<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb29-220"><a href="#cb29-220" aria-hidden="true" tabindex="-1"></a>    ax1.bar(axis2,test_results[<span class="dv">1</span>],label <span class="op">=</span> <span class="st">'Test'</span>,width<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb29-221"><a href="#cb29-221" aria-hidden="true" tabindex="-1"></a>    ax1.set_xlabel(param)</span>
<span id="cb29-222"><a href="#cb29-222" aria-hidden="true" tabindex="-1"></a>    ax1.set_ylabel(<span class="st">"ACCURACY: Training and Test"</span>)</span>
<span id="cb29-223"><a href="#cb29-223" aria-hidden="true" tabindex="-1"></a>    ax1.legend()</span>
<span id="cb29-224"><a href="#cb29-224" aria-hidden="true" tabindex="-1"></a>    ax1.set_xticks([x <span class="op">+</span> <span class="fl">.5</span> <span class="cf">for</span> x <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(test_results))], test_results[<span class="dv">0</span>])</span>
<span id="cb29-225"><a href="#cb29-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-226"><a href="#cb29-226" aria-hidden="true" tabindex="-1"></a>    ax2 <span class="op">=</span> ax[<span class="dv">0</span>,<span class="dv">1</span>]</span>
<span id="cb29-227"><a href="#cb29-227" aria-hidden="true" tabindex="-1"></a>    ax2.bar(axis1,train_results[<span class="dv">2</span>],label <span class="op">=</span> <span class="st">'Train'</span>, width<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb29-228"><a href="#cb29-228" aria-hidden="true" tabindex="-1"></a>    ax2.bar(axis2,test_results[<span class="dv">2</span>],label <span class="op">=</span> <span class="st">'Test'</span>, width<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb29-229"><a href="#cb29-229" aria-hidden="true" tabindex="-1"></a>    ax2.set_xlabel(param)</span>
<span id="cb29-230"><a href="#cb29-230" aria-hidden="true" tabindex="-1"></a>    ax2.legend()</span>
<span id="cb29-231"><a href="#cb29-231" aria-hidden="true" tabindex="-1"></a>    ax2.set_xticks([x <span class="op">+</span> <span class="fl">.5</span> <span class="cf">for</span> x <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(test_results))], test_results[<span class="dv">0</span>])</span>
<span id="cb29-232"><a href="#cb29-232" aria-hidden="true" tabindex="-1"></a>    ax2.set_ylabel(<span class="st">"RECALL(Y=Aetna): Training and Test"</span>)</span>
<span id="cb29-233"><a href="#cb29-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-234"><a href="#cb29-234" aria-hidden="true" tabindex="-1"></a>    ax3 <span class="op">=</span> ax[<span class="dv">0</span>,<span class="dv">2</span>]</span>
<span id="cb29-235"><a href="#cb29-235" aria-hidden="true" tabindex="-1"></a>    ax3.bar(axis1,train_results[<span class="dv">3</span>],label <span class="op">=</span> <span class="st">'Train'</span>, width<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb29-236"><a href="#cb29-236" aria-hidden="true" tabindex="-1"></a>    ax3.bar(axis2,test_results[<span class="dv">3</span>],label <span class="op">=</span> <span class="st">'Test'</span>, width<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb29-237"><a href="#cb29-237" aria-hidden="true" tabindex="-1"></a>    ax3.set_xlabel(param)</span>
<span id="cb29-238"><a href="#cb29-238" aria-hidden="true" tabindex="-1"></a>    ax3.legend()</span>
<span id="cb29-239"><a href="#cb29-239" aria-hidden="true" tabindex="-1"></a>    ax3.set_ylabel(<span class="st">"RECALL(Y=Cigna): Training and Test"</span>)</span>
<span id="cb29-240"><a href="#cb29-240" aria-hidden="true" tabindex="-1"></a>    ax3.set_xticks([x <span class="op">+</span> <span class="fl">.5</span> <span class="cf">for</span> x <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(test_results))], test_results[<span class="dv">0</span>])</span>
<span id="cb29-241"><a href="#cb29-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-242"><a href="#cb29-242" aria-hidden="true" tabindex="-1"></a>    ax4 <span class="op">=</span> ax[<span class="dv">1</span>,<span class="dv">0</span>]</span>
<span id="cb29-243"><a href="#cb29-243" aria-hidden="true" tabindex="-1"></a>    ax4.bar(axis1,train_results[<span class="dv">4</span>],label <span class="op">=</span> <span class="st">'Train'</span>, width<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb29-244"><a href="#cb29-244" aria-hidden="true" tabindex="-1"></a>    ax4.bar(axis2,test_results[<span class="dv">4</span>],label <span class="op">=</span> <span class="st">'Test'</span>, width<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb29-245"><a href="#cb29-245" aria-hidden="true" tabindex="-1"></a>    ax4.set_xlabel(param)</span>
<span id="cb29-246"><a href="#cb29-246" aria-hidden="true" tabindex="-1"></a>    ax4.legend()</span>
<span id="cb29-247"><a href="#cb29-247" aria-hidden="true" tabindex="-1"></a>    ax4.set_ylabel(<span class="st">"RECALL(Y=Anthem): Training and Test"</span>)</span>
<span id="cb29-248"><a href="#cb29-248" aria-hidden="true" tabindex="-1"></a>    ax4.set_xticks([x <span class="op">+</span> <span class="fl">.5</span> <span class="cf">for</span> x <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(test_results))], test_results[<span class="dv">0</span>])</span>
<span id="cb29-249"><a href="#cb29-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-250"><a href="#cb29-250" aria-hidden="true" tabindex="-1"></a>    ax5 <span class="op">=</span> ax[<span class="dv">1</span>,<span class="dv">1</span>]</span>
<span id="cb29-251"><a href="#cb29-251" aria-hidden="true" tabindex="-1"></a>    ax5.bar(axis1,train_results[<span class="dv">5</span>],label <span class="op">=</span> <span class="st">'Train'</span>, width<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb29-252"><a href="#cb29-252" aria-hidden="true" tabindex="-1"></a>    ax5.bar(axis2,test_results[<span class="dv">5</span>],label <span class="op">=</span> <span class="st">'Test'</span>, width<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb29-253"><a href="#cb29-253" aria-hidden="true" tabindex="-1"></a>    ax5.set_xlabel(param)</span>
<span id="cb29-254"><a href="#cb29-254" aria-hidden="true" tabindex="-1"></a>    ax5.legend()</span>
<span id="cb29-255"><a href="#cb29-255" aria-hidden="true" tabindex="-1"></a>    ax5.set_ylabel(<span class="st">"RECALL(Y=UnitedHealth): Training and Test"</span>)</span>
<span id="cb29-256"><a href="#cb29-256" aria-hidden="true" tabindex="-1"></a>    ax5.set_xticks([x <span class="op">+</span> <span class="fl">.5</span> <span class="cf">for</span> x <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(test_results))], test_results[<span class="dv">0</span>])</span>
<span id="cb29-257"><a href="#cb29-257" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-258"><a href="#cb29-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-261"><a href="#cb29-261" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-262"><a href="#cb29-262" aria-hidden="true" tabindex="-1"></a>resultPlot(train_results, test_results, <span class="st">'Gamma'</span>)</span>
<span id="cb29-263"><a href="#cb29-263" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-264"><a href="#cb29-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-265"><a href="#cb29-265" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Regularization (C parameter) Tuning</span>
<span id="cb29-266"><a href="#cb29-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-267"><a href="#cb29-267" aria-hidden="true" tabindex="-1"></a>The regularization (C) parameter tells the SVM optimization how much you want to avoid misclassifying. For large value C, the optimization will chose a smaller-margin hyperplane if that hyperplane does a better job getting all the training points classified correclty. Conversely, a very small C parameter will cause the optimizer to look for a large-margin seperating hyperplane, even if that hyperplane misclassifies more points. The optimized C parameter after tuning is 1. </span>
<span id="cb29-268"><a href="#cb29-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-269"><a href="#cb29-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-272"><a href="#cb29-272" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-273"><a href="#cb29-273" aria-hidden="true" tabindex="-1"></a>test_results<span class="op">=</span>[]</span>
<span id="cb29-274"><a href="#cb29-274" aria-hidden="true" tabindex="-1"></a>train_results<span class="op">=</span>[]</span>
<span id="cb29-275"><a href="#cb29-275" aria-hidden="true" tabindex="-1"></a>C <span class="op">=</span> [<span class="fl">0.1</span>,<span class="fl">1.0</span>,<span class="fl">5.0</span>,<span class="fl">10.0</span>,<span class="fl">50.0</span>,<span class="fl">100.0</span>,<span class="fl">1000.0</span> ]</span>
<span id="cb29-276"><a href="#cb29-276" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> C:</span>
<span id="cb29-277"><a href="#cb29-277" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> SVC(kernel <span class="op">=</span> <span class="st">'sigmoid'</span>, gamma<span class="op">=</span><span class="fl">0.01</span>, C <span class="op">=</span> i)</span>
<span id="cb29-278"><a href="#cb29-278" aria-hidden="true" tabindex="-1"></a>    model.fit(x_train,y_train)</span>
<span id="cb29-279"><a href="#cb29-279" aria-hidden="true" tabindex="-1"></a>    yp_train <span class="op">=</span> model.predict(x_train)</span>
<span id="cb29-280"><a href="#cb29-280" aria-hidden="true" tabindex="-1"></a>    yp_test <span class="op">=</span> model.predict(x_test)</span>
<span id="cb29-281"><a href="#cb29-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-282"><a href="#cb29-282" aria-hidden="true" tabindex="-1"></a>    a,b <span class="op">=</span> tunningResult(y_train, y_test, yp_train, yp_test)</span>
<span id="cb29-283"><a href="#cb29-283" aria-hidden="true" tabindex="-1"></a>    test_results.append([i]<span class="op">+</span>b)</span>
<span id="cb29-284"><a href="#cb29-284" aria-hidden="true" tabindex="-1"></a>    train_results.append([i]<span class="op">+</span>a)</span>
<span id="cb29-285"><a href="#cb29-285" aria-hidden="true" tabindex="-1"></a>test_results <span class="op">=</span> pd.DataFrame(test_results)</span>
<span id="cb29-286"><a href="#cb29-286" aria-hidden="true" tabindex="-1"></a>train_results <span class="op">=</span> pd.DataFrame(train_results)</span>
<span id="cb29-287"><a href="#cb29-287" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-288"><a href="#cb29-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-291"><a href="#cb29-291" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-292"><a href="#cb29-292" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(test_results)</span>
<span id="cb29-293"><a href="#cb29-293" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-294"><a href="#cb29-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-297"><a href="#cb29-297" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-298"><a href="#cb29-298" aria-hidden="true" tabindex="-1"></a>resultPlot(train_results, test_results, <span class="st">'Gamma'</span>)</span>
<span id="cb29-299"><a href="#cb29-299" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-300"><a href="#cb29-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-301"><a href="#cb29-301" aria-hidden="true" tabindex="-1"></a><span class="fu">## Final Result and Conclusion</span></span>
<span id="cb29-302"><a href="#cb29-302" aria-hidden="true" tabindex="-1"></a>In the final model, I used the set of optimized the hyperparameter in SVC to train on the training sets. The result is surprisingly good. According to the printed classification report, the training accuracy is 94.4% and the testing accuracy is around 89%. This means that when we input some new data into this model, the likelihood of outputting the correct label is 89%, which is considered very accurate for a four-label data. We can also double-check the confusion matrix an see that almost all the points are located in the diagnol.</span>
<span id="cb29-305"><a href="#cb29-305" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-306"><a href="#cb29-306" aria-hidden="true" tabindex="-1"></a>final_model <span class="op">=</span> SVC(kernel <span class="op">=</span> <span class="st">'sigmoid'</span>, gamma<span class="op">=</span><span class="fl">0.01</span>, C <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb29-307"><a href="#cb29-307" aria-hidden="true" tabindex="-1"></a>final_model.fit(x_train,y_train)</span>
<span id="cb29-308"><a href="#cb29-308" aria-hidden="true" tabindex="-1"></a>yp_train <span class="op">=</span> final_model.predict(x_train)</span>
<span id="cb29-309"><a href="#cb29-309" aria-hidden="true" tabindex="-1"></a>yp_test <span class="op">=</span> final_model.predict(x_test)</span>
<span id="cb29-310"><a href="#cb29-310" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-311"><a href="#cb29-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-314"><a href="#cb29-314" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-315"><a href="#cb29-315" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'----------------------------Training---------------------------------'</span>)</span>
<span id="cb29-316"><a href="#cb29-316" aria-hidden="true" tabindex="-1"></a>confusion_plot(y_train, yp_train)</span>
<span id="cb29-317"><a href="#cb29-317" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-318"><a href="#cb29-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-321"><a href="#cb29-321" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-322"><a href="#cb29-322" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'----------------------------Testing---------------------------------'</span>)</span>
<span id="cb29-323"><a href="#cb29-323" aria-hidden="true" tabindex="-1"></a>confusion_plot(y_test, yp_test)</span>
<span id="cb29-324"><a href="#cb29-324" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>