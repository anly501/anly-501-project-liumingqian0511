{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk;\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import string \n",
    "import json\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import json\n",
    "import pandas as pd\n",
    "import os, json\n",
    "import glob\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Read in the Json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_to_json = '/Users/liumingqian/anly-501-project-liumingqian0511/data/00-raw-data/twitter_data/'\n",
    "def readFiles(path):\n",
    "    json_pattern = os.path.join(path,'*.json')\n",
    "    file_list = glob.glob(json_pattern)\n",
    "    df = pd.read_json(file_list[0]) # an empty list to store the data frames\n",
    "    #print(df.head())\n",
    "    for file in file_list[1:]:\n",
    "        data = pd.read_json(file) # read data frame from json file\n",
    "        #print(data.head())\n",
    "        df = pd.concat([df,data],axis=0, ignore_index=True) # append the data frame to the list\n",
    "\n",
    "    #df = pd.concat(dfs,sort=False) # concatenate all the data frames in the list.\n",
    "    return df\n",
    "df = readFiles('/Users/liumingqian/anly-501-project-liumingqian0511/data/00-raw-data/insurance_co')\n",
    "df.drop_duplicates(subset = 'text', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json('/Users/liumingqian/anly-501-project-liumingqian0511/data/00-raw-data/insurance_co/Aetna.json')\n",
    "df2 = pd.read_json('/Users/liumingqian/anly-501-project-liumingqian0511/data/00-raw-data/insurance_co/Anthem.json')\n",
    "df3 = pd.read_json('/Users/liumingqian/anly-501-project-liumingqian0511/data/00-raw-data/insurance_co/Cigna.json')\n",
    "df4 = pd.read_json('/Users/liumingqian/anly-501-project-liumingqian0511/data/00-raw-data/insurance_co/Humana.json')\n",
    "df5 = pd.read_json('/Users/liumingqian/anly-501-project-liumingqian0511/data/00-raw-data/insurance_co/UnitedHealth.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Assign Labels Manually and Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['label'] = 'Aetna'\n",
    "df2['label'] = 'Anthem'\n",
    "df3['label'] = 'Cigna'\n",
    "df4['label'] = 'Humana'\n",
    "df5['label'] = 'UnitedHealth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(269, 7)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df1,df2,df3,df4,df5],ignore_index=True)\n",
    "df.drop_duplicates(subset='text',inplace = True)\n",
    "df = df[df['lang'] == 'en']\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Apply Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentiments(df):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    tweet_str = \"\"\n",
    "    tweetscore = []\n",
    "    for tweet in df['text']:\n",
    "        tweet_str = tweet_str + \" \" + tweet\n",
    "        score = sia.polarity_scores(tweet_str)\n",
    "        tweetscore.append(score)\n",
    "    return tweetscore\n",
    "\n",
    "sentiment = getSentiments(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.085</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.7278</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.080</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.8485</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.071</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.8485</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.080</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.9137</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.067</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.051</td>\n",
       "      <td>-0.6116</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.052</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.9533</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.048</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.9692</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     neg    neu    pos  compound  ID\n",
       "0  0.000  1.000  0.000    0.0000   1\n",
       "1  0.000  1.000  0.000    0.0000   2\n",
       "2  0.000  1.000  0.000    0.0000   3\n",
       "3  0.085  0.878  0.037   -0.7278   4\n",
       "4  0.080  0.895  0.025   -0.8485   5\n",
       "5  0.071  0.907  0.022   -0.8485   6\n",
       "6  0.080  0.901  0.019   -0.9137   7\n",
       "7  0.067  0.882  0.051   -0.6116   8\n",
       "8  0.052  0.844  0.104    0.9533   9\n",
       "9  0.048  0.840  0.112    0.9692  10"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = pd.DataFrame.from_dict(sentiment)\n",
    "score = score.assign(ID = list(range(1,len(score)+1)))\n",
    "score.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Add Sentiment Outcome to Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(ID = list(range(1,len(df)+1)))\n",
    "df = df.merge(score,how='inner')\n",
    "df['sentiment'] =df[['neg','neu','pos']].idxmax(axis=1)\n",
    "df['sent_binary'] = df[['neg','pos']].idxmax(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Filter out Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0y/czdjt9k17_9fgxmg3d286zjm0000gn/T/ipykernel_67085/605275336.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'][val] = new_text\n"
     ]
    }
   ],
   "source": [
    "def filterStopwords(df):\n",
    "    for val, tweet in enumerate(df['text']):\n",
    "        new_text=\"\"\n",
    "        for word in nltk.tokenize.word_tokenize(tweet):\n",
    "            word = word.lower()\n",
    "            if word not in nltk.corpus.stopwords.words('english') and word not in [\".\",\",\",\"!\",\"?\",\":\",\";\",\")\",\"(\",\"'\",\"$\",'https','co','rt','@','de','la','the']:\n",
    "                    new_text+=word+\" \"\n",
    "            df['text'][val] = new_text\n",
    "\n",
    "filterStopwords(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f) Lemmatize Text Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(df):\n",
    "    for i,tweet in enumerate(df['text']):\n",
    "        new_text = \"\"\n",
    "        for word in tweet.split(' '):\n",
    "            if wn.synsets(word):\n",
    "                new_text += lemmatizer.lemmatize(word,pos= wn.synsets(word)[0].pos()) + \" \"\n",
    "            else:\n",
    "                new_text += word + \" \"\n",
    "        df['text'][i] = new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0y/czdjt9k17_9fgxmg3d286zjm0000gn/T/ipykernel_67085/4089900633.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'][i] = new_text\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>edit_history_tweet_ids</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>lang</th>\n",
       "      <th>author_id</th>\n",
       "      <th>label</th>\n",
       "      <th>ID</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sent_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1579944177819070464</td>\n",
       "      <td>[1579944177819070465]</td>\n",
       "      <td>loyolaramblers 𝗧𝗵𝗲 𝗥𝗮𝗺𝗯𝗹𝗲𝗿 𝗥𝗼𝘂𝗻𝗱𝘁𝗮𝗯𝗹𝗲 present ...</td>\n",
       "      <td>2022-10-11 21:17:00+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>1015398717392687104</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neu</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1579940514522370048</td>\n",
       "      <td>[1579940514522370048]</td>\n",
       "      <td>pom_pnw aetna give directory resident house ad...</td>\n",
       "      <td>2022-10-11 21:02:27+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>1325197299409182720</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neu</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1579937294152519680</td>\n",
       "      <td>[1579937294152519680]</td>\n",
       "      <td>peds_ortho aetna ’ doctor ’ office take copay ...</td>\n",
       "      <td>2022-10-11 20:49:39+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>1228846428929380352</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neu</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1579934089695875072</td>\n",
       "      <td>[1579934089695875072]</td>\n",
       "      <td>aetna twice deny necessary medication b/c what...</td>\n",
       "      <td>2022-10-11 20:36:55+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>1077754392433082368</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>4</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.7278</td>\n",
       "      <td>neu</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1579932311864238080</td>\n",
       "      <td>[1579932311864238080]</td>\n",
       "      <td>peds_ortho aetna pay copay meet oop limit ’ pa...</td>\n",
       "      <td>2022-10-11 20:29:51+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>1228846428929380352</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>5</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.8485</td>\n",
       "      <td>neu</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id edit_history_tweet_ids  \\\n",
       "0  1579944177819070464  [1579944177819070465]   \n",
       "1  1579940514522370048  [1579940514522370048]   \n",
       "2  1579937294152519680  [1579937294152519680]   \n",
       "3  1579934089695875072  [1579934089695875072]   \n",
       "4  1579932311864238080  [1579932311864238080]   \n",
       "\n",
       "                                                text  \\\n",
       "0  loyolaramblers 𝗧𝗵𝗲 𝗥𝗮𝗺𝗯𝗹𝗲𝗿 𝗥𝗼𝘂𝗻𝗱𝘁𝗮𝗯𝗹𝗲 present ...   \n",
       "1  pom_pnw aetna give directory resident house ad...   \n",
       "2  peds_ortho aetna ’ doctor ’ office take copay ...   \n",
       "3  aetna twice deny necessary medication b/c what...   \n",
       "4  peds_ortho aetna pay copay meet oop limit ’ pa...   \n",
       "\n",
       "                 created_at lang            author_id  label  ID    neg  \\\n",
       "0 2022-10-11 21:17:00+00:00   en  1015398717392687104  Aetna   1  0.000   \n",
       "1 2022-10-11 21:02:27+00:00   en  1325197299409182720  Aetna   2  0.000   \n",
       "2 2022-10-11 20:49:39+00:00   en  1228846428929380352  Aetna   3  0.000   \n",
       "3 2022-10-11 20:36:55+00:00   en  1077754392433082368  Aetna   4  0.085   \n",
       "4 2022-10-11 20:29:51+00:00   en  1228846428929380352  Aetna   5  0.080   \n",
       "\n",
       "     neu    pos  compound sentiment sent_binary  \n",
       "0  1.000  0.000    0.0000       neu         neg  \n",
       "1  1.000  0.000    0.0000       neu         neg  \n",
       "2  1.000  0.000    0.0000       neu         neg  \n",
       "3  0.878  0.037   -0.7278       neu         neg  \n",
       "4  0.895  0.025   -0.8485       neu         neg  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g) Tidy Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>language</th>\n",
       "      <th>label</th>\n",
       "      <th>ID</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sent_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>loyolaramblers 𝗧𝗵𝗲 𝗥𝗮𝗺𝗯𝗹𝗲𝗿 𝗥𝗼𝘂𝗻𝗱𝘁𝗮𝗯𝗹𝗲 present ...</td>\n",
       "      <td>2022-10-11</td>\n",
       "      <td>en</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>1</td>\n",
       "      <td>neu</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pom_pnw aetna give directory resident house ad...</td>\n",
       "      <td>2022-10-11</td>\n",
       "      <td>en</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>2</td>\n",
       "      <td>neu</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>peds_ortho aetna ’ doctor ’ office take copay ...</td>\n",
       "      <td>2022-10-11</td>\n",
       "      <td>en</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>3</td>\n",
       "      <td>neu</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aetna twice deny necessary medication b/c what...</td>\n",
       "      <td>2022-10-11</td>\n",
       "      <td>en</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>4</td>\n",
       "      <td>neu</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>peds_ortho aetna pay copay meet oop limit ’ pa...</td>\n",
       "      <td>2022-10-11</td>\n",
       "      <td>en</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>5</td>\n",
       "      <td>neu</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text        date language  \\\n",
       "0  loyolaramblers 𝗧𝗵𝗲 𝗥𝗮𝗺𝗯𝗹𝗲𝗿 𝗥𝗼𝘂𝗻𝗱𝘁𝗮𝗯𝗹𝗲 present ...  2022-10-11       en   \n",
       "1  pom_pnw aetna give directory resident house ad...  2022-10-11       en   \n",
       "2  peds_ortho aetna ’ doctor ’ office take copay ...  2022-10-11       en   \n",
       "3  aetna twice deny necessary medication b/c what...  2022-10-11       en   \n",
       "4  peds_ortho aetna pay copay meet oop limit ’ pa...  2022-10-11       en   \n",
       "\n",
       "   label  ID sentiment sent_binary  \n",
       "0  Aetna   1       neu         neg  \n",
       "1  Aetna   2       neu         neg  \n",
       "2  Aetna   3       neu         neg  \n",
       "3  Aetna   4       neu         neg  \n",
       "4  Aetna   5       neu         neg  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['created_at'] = df['created_at'].apply(lambda x: x.date)\n",
    "df.rename(columns={'created_at':'date','lang':'language'},inplace = True)\n",
    "df.drop(columns = ['author_id','id','edit_history_tweet_ids','neg','pos','neu','compound'],inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### h) Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_str = \"\"\n",
    "corpus = []\n",
    "df['text'].apply(lambda x: corpus.append(x))\n",
    "corpus_str = corpus_str.join(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>08</th>\n",
       "      <th>0bl5dzrcc2</th>\n",
       "      <th>0cfllxypoq</th>\n",
       "      <th>0skzqs8f8h</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>...</th>\n",
       "      <th>yoy</th>\n",
       "      <th>yuvo</th>\n",
       "      <th>z4wc2sk8ji</th>\n",
       "      <th>zero</th>\n",
       "      <th>zoryalondonsk</th>\n",
       "      <th>zwsyhywsgy</th>\n",
       "      <th>𝗥𝗮𝗺𝗯𝗹𝗲𝗿</th>\n",
       "      <th>𝗥𝗼𝘂𝗻𝗱𝘁𝗮𝗯𝗹𝗲</th>\n",
       "      <th>𝗧𝗵𝗲</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Aetna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Aetna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Aetna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Aetna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Aetna</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2162 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  01  02  08  0bl5dzrcc2  0cfllxypoq  0skzqs8f8h  10  100  ...  yoy  \\\n",
       "0   0    0   0   0   0           0           0           0   0    0  ...    0   \n",
       "1   0    0   0   0   0           0           0           0   0    0  ...    0   \n",
       "2   0    0   0   0   0           0           0           0   0    0  ...    0   \n",
       "3   0    0   0   0   0           0           0           0   0    0  ...    0   \n",
       "4   0    0   0   0   0           0           0           0   0    0  ...    0   \n",
       "\n",
       "   yuvo  z4wc2sk8ji  zero  zoryalondonsk  zwsyhywsgy  𝗥𝗮𝗺𝗯𝗹𝗲𝗿  𝗥𝗼𝘂𝗻𝗱𝘁𝗮𝗯𝗹𝗲  \\\n",
       "0     0           0     0              0           0        1           1   \n",
       "1     0           0     0              0           0        0           0   \n",
       "2     0           0     0              0           0        0           0   \n",
       "3     0           0     0              0           0        0           0   \n",
       "4     0           0     0              0           0        0           0   \n",
       "\n",
       "   𝗧𝗵𝗲  label  \n",
       "0    1  Aetna  \n",
       "1    0  Aetna  \n",
       "2    0  Aetna  \n",
       "3    0  Aetna  \n",
       "4    0  Aetna  \n",
       "\n",
       "[5 rows x 2162 columns]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer=CountVectorizer()\n",
    "Xs  =  vectorizer.fit_transform(corpus)\n",
    "X = np.array(Xs.todense())\n",
    "col_names=vectorizer.get_feature_names_out()\n",
    "vec = pd.DataFrame(X,columns=col_names)\n",
    "vec['label'] = df['label']\n",
    "vec.to_csv('/Users/liumingqian/anly-501-project-liumingqian0511/data/01-modified-data/vec.csv')\n",
    "vec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>co</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cigna</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aetna</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anthem</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unitedhealth</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>health</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>get</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>group</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>amp</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>plan</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  Frequency\n",
       "0            co        146\n",
       "1         cigna         81\n",
       "2         aetna         77\n",
       "3        anthem         53\n",
       "4  unitedhealth         49\n",
       "5        health         40\n",
       "6           get         29\n",
       "7         group         29\n",
       "8           amp         28\n",
       "9          plan         27"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_words = Xs.sum(axis=0) \n",
    "words_freq = [[word, sum_words[0, idx]] for word, idx in vectorizer.vocabulary_.items()]\n",
    "words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "words_freq_df = pd.DataFrame(words_freq,columns=['word','Frequency'])\n",
    "words_freq_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_freq_df.to_csv('/Users/liumingqian/anly-501-project-liumingqian0511/data/01-modified-data/word_frequency_text.csv')\n",
    "df.to_csv('/Users/liumingqian/anly-501-project-liumingqian0511/data/01-modified-data/text.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ANLY501')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c7b1725a53a00cadd46ef15f4ed641a76ecf8b551f4473e176c4bcc6f018dcb6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
